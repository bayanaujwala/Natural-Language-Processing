{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc97d6da",
   "metadata": {
    "id": "bc97d6da"
   },
   "source": [
    "## CS 6120: Natural Language Processing - Prof. Ahmad Uzair\n",
    "\n",
    "### Assignment 1: Naive Bayes\n",
    "### Total Points: 100 points\n",
    "\n",
    "You will be dealing with movie review data that includes both positive and negative reviews in this assignment. You will use Sentiment Analysis to assess if a given review is positive or negative using the provided dataset.\n",
    "\n",
    "Therefore, we will make use of Naive Bayes algorithm to perform sentiment analysis on the movie review dataset.\n",
    "\n",
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03450ac",
   "metadata": {
    "id": "a03450ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('omw-1.4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc584cc2",
   "metadata": {
    "id": "fc584cc2"
   },
   "source": [
    "## Reading the data\n",
    "\n",
    "When reading the data, ensure that the '.csv' file is in the same location where your jupyter notebook is used. This way the files are organized and easy to read using the pandas library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9ffbf5",
   "metadata": {
    "id": "3c9ffbf5"
   },
   "outputs": [],
   "source": [
    "## Reading the data and removing columns that are not important. \n",
    "df = pd.read_csv(\"C:\\\\Datasets\\\\movie_reviews-1.csv\", sep = ',', encoding = 'latin-1', usecols = lambda col: col not in [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fa8ac0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f7fa8ac0",
    "outputId": "69edaf28-1e2e-4ec7-9530-b30a2853ab9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "4  Probably my all-time favorite movie, a story o...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print head of data frame with help of head function\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749da04",
   "metadata": {
    "id": "1749da04"
   },
   "source": [
    "## Count plot of the output categories: positive or negative\n",
    "\n",
    "Feel free to take a look at the output and whether the classes are balanced or imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c152e8a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "c152e8a4",
    "outputId": "a2ba0476-3238-4511-fcf0-780508493f48"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "sns.countplot(x=\"sentiment\", data=df)\n",
    "plt.title(\"Positive Vs. Negative reviews count\", fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8549f2",
   "metadata": {
    "id": "9b8549f2"
   },
   "source": [
    "## Upsampling the minority class: (5 points)\n",
    "\n",
    "It is known that Naive bayes is not robust to class imbalance. It could be seen above that the data is little imbalanced. Therefore, class balancing can be done before giving it to the Naive Bayes model for prediction. \n",
    "\n",
    "Feel free to use 'resample' library from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yHJTAqrW7XMN",
   "metadata": {
    "id": "yHJTAqrW7XMN"
   },
   "outputs": [],
   "source": [
    "## hint: use resample from sklearn.utils\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['sentiment'] == 'positive']\n",
    "df_minority = df[df['sentiment'] == 'negative']\n",
    "\n",
    "negative_upsample = resample(df_minority, replace = True, \n",
    "                        n_samples = df_majority.shape[0],\n",
    "                        random_state = 101)\n",
    "\n",
    "df_upsampled = pd.concat([negative_upsample, df_majority])  # concat two data frames i,e majority class data set and upsampled minority class data set\n",
    "df_upsampled = df_upsampled.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9329bb",
   "metadata": {
    "id": "6a9329bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12474, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just to ensure that upsampling was done successfully, take a look at the shape of the data in \n",
    "## this cell. \n",
    "\n",
    "# print the shape of data set with the help of shape function having \"negative\" as class label\n",
    "df_upsampled[df_upsampled.sentiment=='negative'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bf6e7",
   "metadata": {
    "id": "6f8bf6e7"
   },
   "source": [
    "### Expected Output : \n",
    "(12474, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdea8155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdea8155",
    "outputId": "c665c4b9-826e-4f4e-e30e-06e0935a0622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12474, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensure that the same number of data points are present for both 'positive' and 'negative' data\n",
    "\n",
    "# print the shape of data set with the help of shape function having \"positive\" as class label\n",
    "df_upsampled[df_upsampled.sentiment=='positive'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f01d5",
   "metadata": {
    "id": "626f01d5"
   },
   "source": [
    "### Expected Output : \n",
    "(12474, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "NoW5z6SzAeP8",
   "metadata": {
    "id": "NoW5z6SzAeP8"
   },
   "outputs": [],
   "source": [
    "## In this cell, we are going to be dividing the data into train and test points\n",
    "## Ensure that you store the upsampled data in a variable called 'df_upsampled' \n",
    "## so that the below operations are performed successfully\n",
    "\n",
    "\n",
    "## Considering 10000 positive and 10000 negative data points\n",
    "negative_data_points_train = df_upsampled[df_upsampled.sentiment=='negative'].iloc[:10000]\n",
    "positive_data_points_train = df_upsampled[df_upsampled.sentiment=='positive'].iloc[:10000]\n",
    "\n",
    "## Considering the remaining data points for test\n",
    "negative_data_points_test = df_upsampled[df_upsampled.sentiment=='negative'].iloc[10000:]\n",
    "positive_data_points_test = df_upsampled[df_upsampled.sentiment=='positive'].iloc[10000:]\n",
    "\n",
    "## Concatenate the training positive and negative reviews\n",
    "X_train = pd.concat([negative_data_points_train.review, positive_data_points_train.review])\n",
    "## Concatenating the training positive and negative outputs\n",
    "y_train = pd.concat([negative_data_points_train.sentiment, positive_data_points_train.sentiment])\n",
    "\n",
    "## Concatenating the test positive and negative reviews\n",
    "X_test = pd.concat([negative_data_points_test.review, positive_data_points_test.review])\n",
    "## Concatenating the test positive and negative outputs\n",
    "y_test = pd.concat([negative_data_points_test.sentiment, positive_data_points_test.sentiment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6428047d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6428047d",
    "outputId": "10d10601-0ce0-4688-c4d3-75fa386583fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    10000\n",
       "positive    10000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Take a look at the total number of classes and their count using '.value_counts()' for y_train and y_test.\n",
    "## Ensure that there are equal number of positive and negative reviews. \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe6517",
   "metadata": {
    "id": "7dfe6517"
   },
   "source": [
    "### Expected Output:\n",
    "negative    10000<br>\n",
    "positive    10000<br>\n",
    "Name: sentiment, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2beae1d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2beae1d6",
    "outputId": "6896f930-6a1a-45db-b74c-d080c9aedd0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2474\n",
       "positive    2474\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163f897",
   "metadata": {
    "id": "9163f897"
   },
   "source": [
    "### Expected Output : \n",
    "negative    2474<br>\n",
    "positive    2474<br>\n",
    "Name: sentiment, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501699b",
   "metadata": {
    "id": "6501699b"
   },
   "source": [
    "## Q1. Pre-process the reviews: (10 points)\n",
    "\n",
    "We know that a review contains links, punctuation, stopwords and many other words that don't give a lot of meaning for the Naive Bayes model for prediction. \n",
    "\n",
    "In the cell below, one must implement text-preprocessing and remove links, punctuations and stopwords. It is also important to lowercase the letters so that 'Admire' and 'admire' are not treated as different words. \n",
    "\n",
    "In addition to this, perform stemming operation so that similar words are reduced. To know more about stemming, feel free to take a look at this link.\n",
    "\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CirLN9-ddQ1r",
   "metadata": {
    "id": "CirLN9-ddQ1r"
   },
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_review(review):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string containing a review.\n",
    "    Output:\n",
    "        review_cleaned: a processed review. \n",
    "        \n",
    "    '''\n",
    "    # Converting to lower case\n",
    "    review = review.lower() \n",
    "    # removing the links\n",
    "    review = re.sub(r'https?://\\S+', '', review) \n",
    "    # removing the punctuations\n",
    "    review = re.sub(r'[^\\w\\s]', '', review)\n",
    "    # tokenizing \n",
    "    review = word_tokenize(review)\n",
    "    # removing stop words\n",
    "    review = [word for word in review if word not in stopwords]\n",
    "    # Lemmatizing input \n",
    "    review_cleaned = [lemmatizer.lemmatize(w) for w in review]\n",
    "    \n",
    "    \n",
    "    return review_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7632fe5",
   "metadata": {
    "id": "a7632fe5"
   },
   "source": [
    "## Q2. Implement a find_occurrence function (5 points):\n",
    "\n",
    "In this function, we find the total occurrence of a word giving information such as label, word and frequency dictionary.\n",
    "\n",
    "Note that this function is used later in the code when we are going to be predicting the output using Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb282b81",
   "metadata": {
    "id": "eb282b81"
   },
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "def find_occurrence(frequency, word, label):\n",
    "    \n",
    "    '''\n",
    "    Params:\n",
    "        frequency: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Return:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = frequency[(word,label)] if (word,label) in frequency.keys() else 0\n",
    "  \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a2249d",
   "metadata": {
    "id": "29a2249d"
   },
   "source": [
    "### Converting output to numerical format:\n",
    "\n",
    "We have outputs as 'positive' or 'negative'. In the cell below, we convert it to a numerical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcdc2b2c",
   "metadata": {
    "id": "bcdc2b2c"
   },
   "outputs": [],
   "source": [
    "## With the use of mapping function, we replace\n",
    "## the label in the form of string to an integer. \n",
    "\n",
    "output_map = {'positive': 0, 'negative': 1}\n",
    "y_train = y_train.map(output_map)\n",
    "y_test = y_test.map(output_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dde0bbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dde0bbd",
    "outputId": "223dfbc1-8efe-4183-b6d7-c9cb025cb285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensuring that there are equal number of classes on the training data. \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2959b85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "f2959b85",
    "outputId": "e514214b-cd57-43fc-875d-1821ddab63f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Turgid dialogue, feeble characterization - Harvey Keitel a judge? He plays more like an off-duty hitman - and a tension-free plot conspire to make one of the unfunniest films of all time. You feel sorry for the cast as they try to extract comedy from a dire and lifeless script. Avoid!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Choosing a random review and taking a look at it.\n",
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e43c9",
   "metadata": {
    "id": "ed5e43c9"
   },
   "source": [
    "From the above cell output, it could be seen that there are a lot of words that don't add a lot of meaning to the text. \n",
    "\n",
    "Therefore, those words would be removed. It also reduces the computation time. \n",
    "\n",
    "Therefore, it is a good practice we are following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3937ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad3937ea",
    "outputId": "68985efe-32cd-4c11-ed5b-2e1e1b297e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turgid', 'dialogue', 'feeble', 'characterization', 'harvey', 'keitel', 'judge', 'play', 'like', 'offduty', 'hitman', 'tensionfree', 'plot', 'conspire', 'make', 'one', 'unfunniest', 'film', 'time', 'feel', 'sorry', 'cast', 'try', 'extract', 'comedy', 'dire', 'lifeless', 'script', 'avoid']\n"
     ]
    }
   ],
   "source": [
    "custom_review = X_train.iloc[0]\n",
    "\n",
    "# print cleaned review\n",
    "print(clean_review(custom_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cc440",
   "metadata": {
    "id": "3e6cc440"
   },
   "source": [
    "We now use this function to pre-process the review and remove words that don't add a lot of meaning in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a762960",
   "metadata": {
    "id": "5a762960"
   },
   "source": [
    "## Q3. Implementing review counter function: (5 points)\n",
    "\n",
    "It is now time to implement the count function for the reviews. \n",
    "\n",
    "In this function, we count the occurrence of words and get the probabilities \n",
    "for the words based on the training data. \n",
    "\n",
    "In other words, we get the probability of occurrence of a word, given that the output is 'positive'.\n",
    "\n",
    "Similarly, we also compute the probability of occurence of a word, given that the output is 'negative'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5de61f77",
   "metadata": {
    "id": "5de61f77"
   },
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "def review_counter(output_occurrence, reviews, positive_or_negative):\n",
    "    '''\n",
    "    Params:\n",
    "        output_occurrence: a dictionary that will be used to map each pair to its frequency\n",
    "        reviews: a list of reviews\n",
    "        positive_or_negative: a list corresponding to the sentiment of each review (either 0 or 1)\n",
    "    Return:\n",
    "        output: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    ## Steps :\n",
    "    # define the key, which is the word and label tuple\n",
    "    # if the key exists in the dictionary, increment the count\n",
    "    # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "    \n",
    "    for label, review in zip(positive_or_negative, reviews):\n",
    "        split_review = clean_review(review)\n",
    "        for word in split_review:\n",
    "            if (word,label) in output_occurrence.keys():\n",
    "                output_occurrence[(word,label)] += 1\n",
    "            else:\n",
    "                output_occurrence[(word,label)] = 1\n",
    "\n",
    "    return output_occurrence\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18238223",
   "metadata": {
    "id": "18238223"
   },
   "source": [
    "### Test your function with example reviews:\n",
    "\n",
    "Feel free to run the cell below and understand whether the above function that you have defined is producing the optimum results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a4c58a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07a4c58a",
    "outputId": "dd9e148a-34a9-4cfe-9077-c5de33493d7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('got', 1): 1,\n",
       " ('bored', 1): 2,\n",
       " ('throught', 1): 1,\n",
       " ('moview', 1): 1,\n",
       " ('movie', 0): 2,\n",
       " ('fantastic', 0): 1,\n",
       " ('watch', 1): 1,\n",
       " ('complete', 1): 1,\n",
       " ('waste', 1): 1,\n",
       " ('time', 1): 1,\n",
       " ('money', 1): 1,\n",
       " ('enjoyed', 0): 1,\n",
       " ('fullest', 0): 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing your function\n",
    "\n",
    "result = {}\n",
    "reviews = ['got bored throught the moview', 'The movie was fantastic', 'Will not watch it again', 'Was bored, it was a complete waste of time and money', 'Enjoyed the movie to the fullest']\n",
    "ys = [1, 0, 1, 1, 0]\n",
    "review_counter(result,reviews, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f89bb",
   "metadata": {
    "id": "927f89bb"
   },
   "source": [
    "### Expected Output:\n",
    " {('bored', 1): 2, <br>\n",
    " ('complete', 1): 1, <br>\n",
    " ('enjoyed', 0): 1, <br>\n",
    " ('fantastic', 0): 1, <br>\n",
    " ('fullest', 0): 1, <br>\n",
    " ('got', 1): 1, <br>\n",
    " ('money', 1): 1, <br>\n",
    " ('movie', 0): 2, <br>\n",
    " ('moview', 1): 1, <br>\n",
    " ('throught', 1): 1, <br>\n",
    " ('time', 1): 1, <br>\n",
    " ('waste', 1): 1, <br>\n",
    " ('watch', 1): 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bc62e13",
   "metadata": {
    "id": "9bc62e13"
   },
   "outputs": [],
   "source": [
    "# Build the freqs dictionary for later uses\n",
    "\n",
    "freqs = review_counter({}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eddf420",
   "metadata": {
    "id": "0eddf420"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('turgid', 1): 30,\n",
       " ('dialogue', 1): 849,\n",
       " ('feeble', 1): 20,\n",
       " ('characterization', 1): 74,\n",
       " ('harvey', 1): 32,\n",
       " ('keitel', 1): 17,\n",
       " ('judge', 1): 129,\n",
       " ('play', 1): 1354,\n",
       " ('like', 1): 8950,\n",
       " ('offduty', 1): 4,\n",
       " ('hitman', 1): 17,\n",
       " ('tensionfree', 1): 5,\n",
       " ('plot', 1): 3323,\n",
       " ('conspire', 1): 5,\n",
       " ('make', 1): 5069,\n",
       " ('one', 1): 10389,\n",
       " ('unfunniest', 1): 5,\n",
       " ('film', 1): 16764,\n",
       " ('time', 1): 5759,\n",
       " ('feel', 1): 1455,\n",
       " ('sorry', 1): 481,\n",
       " ('cast', 1): 1390,\n",
       " ('try', 1): 1388,\n",
       " ('extract', 1): 18,\n",
       " ('comedy', 1): 1305,\n",
       " ('dire', 1): 65,\n",
       " ('lifeless', 1): 63,\n",
       " ('script', 1): 1718,\n",
       " ('avoid', 1): 496,\n",
       " ('movie', 1): 22404,\n",
       " ('came', 1): 649,\n",
       " ('huge', 1): 371,\n",
       " ('disappointment', 1): 218,\n",
       " ('anime', 1): 68,\n",
       " ('series', 1): 909,\n",
       " ('ended', 1): 245,\n",
       " ('relatively', 1): 72,\n",
       " ('stupid', 1): 1159,\n",
       " ('twist', 1): 369,\n",
       " ('rushed', 1): 59,\n",
       " ('introduction', 1): 77,\n",
       " ('pretty', 1): 1710,\n",
       " ('lame', 1): 474,\n",
       " ('villain', 1): 350,\n",
       " ('expected', 1): 308,\n",
       " ('shamballa', 1): 3,\n",
       " ('tie', 1): 74,\n",
       " ('loose', 1): 111,\n",
       " ('end', 1): 2480,\n",
       " ('unfortunately', 1): 725,\n",
       " ('didnt', 1): 2087,\n",
       " ('added', 1): 185,\n",
       " ('hole', 1): 278,\n",
       " ('resolved', 1): 37,\n",
       " ('confused', 1): 142,\n",
       " ('clarified', 1): 3,\n",
       " ('animation', 1): 197,\n",
       " ('voice', 1): 451,\n",
       " ('acting', 1): 3208,\n",
       " ('great', 1): 2116,\n",
       " ('idiotic', 1): 125,\n",
       " ('dull', 1): 521,\n",
       " ('setting', 1): 242,\n",
       " ('doesnt', 1): 2045,\n",
       " ('even', 1): 6156,\n",
       " ('take', 1): 2114,\n",
       " ('place', 1): 1034,\n",
       " ('wwii', 1): 40,\n",
       " ('earth', 1): 365,\n",
       " ('rather', 1): 1082,\n",
       " ('alchemy', 1): 9,\n",
       " ('world', 1): 1004,\n",
       " ('disappointing', 1): 251,\n",
       " ('ending', 1): 890,\n",
       " ('ed', 1): 152,\n",
       " ('useless', 1): 77,\n",
       " ('rest', 1): 786,\n",
       " ('day', 1): 1312,\n",
       " ('ditch', 1): 13,\n",
       " ('winry', 1): 3,\n",
       " ('altogether', 1): 46,\n",
       " ('lackluster', 1): 48,\n",
       " ('favor', 1): 130,\n",
       " ('disregard', 1): 22,\n",
       " ('last', 1): 1147,\n",
       " ('half', 1): 950,\n",
       " ('well', 1): 3101,\n",
       " ('read', 1): 935,\n",
       " ('manga', 1): 21,\n",
       " ('good', 1): 5810,\n",
       " ('old', 1): 1483,\n",
       " ('jess', 1): 38,\n",
       " ('franco', 1): 75,\n",
       " ('alwaysreliable', 1): 3,\n",
       " ('choice', 1): 227,\n",
       " ('director', 1): 2033,\n",
       " ('case', 1): 667,\n",
       " ('youre', 1): 927,\n",
       " ('looking', 1): 1129,\n",
       " ('undemanding', 1): 11,\n",
       " ('sleaze', 1): 69,\n",
       " ('shameless', 1): 33,\n",
       " ('exploitation', 1): 117,\n",
       " ('200', 1): 35,\n",
       " ('gratuitousness', 1): 2,\n",
       " ('really', 1): 5021,\n",
       " ('surpassed', 1): 14,\n",
       " ('utterly', 1): 211,\n",
       " ('trashy', 1): 67,\n",
       " ('piece', 1): 864,\n",
       " ('jungle', 1): 113,\n",
       " ('adventure', 1): 128,\n",
       " ('let', 1): 1227,\n",
       " ('face', 1): 760,\n",
       " ('basically', 1): 490,\n",
       " ('excuse', 1): 292,\n",
       " ('ravishingly', 1): 2,\n",
       " ('hot', 1): 338,\n",
       " ('underageâ', 1): 2,\n",
       " ('actress', 1): 555,\n",
       " ('katja', 1): 6,\n",
       " ('bienert', 1): 4,\n",
       " ('parade', 1): 37,\n",
       " ('around', 1): 1452,\n",
       " ('topless', 1): 68,\n",
       " ('actually', 1): 2028,\n",
       " ('disturbing', 1): 174,\n",
       " ('thought', 1): 1439,\n",
       " ('innocent', 1): 114,\n",
       " ('16yearold', 1): 2,\n",
       " ('girl', 1): 1631,\n",
       " ('walk', 1): 304,\n",
       " ('set', 1): 1228,\n",
       " ('naked', 1): 240,\n",
       " ('front', 1): 230,\n",
       " ('whole', 1): 1427,\n",
       " ('crew', 1): 292,\n",
       " ('particularly', 1): 408,\n",
       " ('gazing', 1): 9,\n",
       " ('eye', 1): 601,\n",
       " ('pervert', 1): 23,\n",
       " ('wasnt', 1): 1114,\n",
       " ('first', 1): 3324,\n",
       " ('since', 1): 1103,\n",
       " ('duo', 1): 42,\n",
       " ('previously', 1): 68,\n",
       " ('already', 1): 604,\n",
       " ('made', 1): 3402,\n",
       " ('linda', 1): 63,\n",
       " ('together', 1): 741,\n",
       " ('anyways', 1): 60,\n",
       " ('wondered', 1): 53,\n",
       " ('yes', 1): 643,\n",
       " ('diamond', 1): 56,\n",
       " ('kilimanjaro', 1): 4,\n",
       " ('albeit', 1): 52,\n",
       " ('imbecilic', 1): 11,\n",
       " ('opening', 1): 389,\n",
       " ('sequence', 1): 631,\n",
       " ('plane', 1): 193,\n",
       " ('carrying', 1): 60,\n",
       " ('aboard', 1): 32,\n",
       " ('wealthy', 1): 49,\n",
       " ('scottish', 1): 24,\n",
       " ('guy', 1): 2167,\n",
       " ('child', 1): 887,\n",
       " ('crash', 1): 134,\n",
       " ('amidst', 1): 17,\n",
       " ('african', 1): 81,\n",
       " ('tribe', 1): 56,\n",
       " ('vegetarian', 1): 7,\n",
       " ('cannibal', 1): 79,\n",
       " ('say', 1): 2801,\n",
       " ('never', 1): 2781,\n",
       " ('point', 1): 1663,\n",
       " ('much', 1): 3864,\n",
       " ('attempt', 1): 907,\n",
       " ('consume', 1): 7,\n",
       " ('human', 1): 553,\n",
       " ('flesh', 1): 99,\n",
       " ('obnoxious', 1): 101,\n",
       " ('scot', 1): 12,\n",
       " ('declares', 1): 19,\n",
       " ('white', 1): 493,\n",
       " ('leader', 1): 116,\n",
       " ('grows', 1): 49,\n",
       " ('become', 1): 488,\n",
       " ('beautiful', 1): 536,\n",
       " ('scarcely', 1): 14,\n",
       " ('dressed', 1): 128,\n",
       " ('goddess', 1): 27,\n",
       " ('several', 1): 533,\n",
       " ('year', 1): 2062,\n",
       " ('later', 1): 706,\n",
       " ('expedition', 1): 18,\n",
       " ('reach', 1): 120,\n",
       " ('middle', 1): 345,\n",
       " ('get', 1): 5291,\n",
       " ('back', 1): 1785,\n",
       " ('civilization', 1): 26,\n",
       " ('â', 1): 745,\n",
       " ('importantly', 1): 48,\n",
       " ('steal', 1): 184,\n",
       " ('legendary', 1): 61,\n",
       " ('could', 1): 3717,\n",
       " ('compelling', 1): 98,\n",
       " ('actionpacked', 1): 12,\n",
       " ('obviously', 1): 603,\n",
       " ('couldnt', 1): 840,\n",
       " ('bothered', 1): 95,\n",
       " ('shoot', 1): 305,\n",
       " ('chase', 1): 244,\n",
       " ('bloody', 1): 133,\n",
       " ('cannibalistic', 1): 13,\n",
       " ('rite', 1): 14,\n",
       " ('easily', 1): 290,\n",
       " ('aim', 1): 51,\n",
       " ('camera', 1): 901,\n",
       " ('young', 1): 992,\n",
       " ('chick', 1): 197,\n",
       " ('sitting', 1): 251,\n",
       " ('tree', 1): 135,\n",
       " ('simply', 1): 864,\n",
       " ('appear', 1): 279,\n",
       " ('filmed', 1): 264,\n",
       " ('someone', 1): 1223,\n",
       " ('garden', 1): 57,\n",
       " ('there', 1): 1423,\n",
       " ('massive', 1): 92,\n",
       " ('amount', 1): 214,\n",
       " ('clumsily', 1): 21,\n",
       " ('edited', 1): 143,\n",
       " ('national', 1): 88,\n",
       " ('geographic', 1): 10,\n",
       " ('wildlife', 1): 8,\n",
       " ('footage', 1): 313,\n",
       " ('order', 1): 426,\n",
       " ('fill', 1): 143,\n",
       " ('gap', 1): 30,\n",
       " ('continuity', 1): 106,\n",
       " ('dvd', 1): 771,\n",
       " ('describes', 1): 36,\n",
       " ('ingenious', 1): 6,\n",
       " ('feminist', 1): 24,\n",
       " ('adult', 1): 261,\n",
       " ('orientated', 1): 7,\n",
       " ('version', 1): 753,\n",
       " ('tarzan', 1): 94,\n",
       " ('yeah', 1): 221,\n",
       " ('right', 1): 1314,\n",
       " ('put', 1): 1177,\n",
       " ('sentence', 1): 81,\n",
       " ('bienerts', 1): 2,\n",
       " ('character', 1): 5598,\n",
       " ('swing', 1): 27,\n",
       " ('another', 1): 1678,\n",
       " ('using', 1): 358,\n",
       " ('couple', 1): 794,\n",
       " ('college', 1): 213,\n",
       " ('student', 1): 324,\n",
       " ('late', 1): 330,\n",
       " ('20', 1): 321,\n",
       " ('campus', 1): 26,\n",
       " ('boston', 1): 28,\n",
       " ('look', 1): 2890,\n",
       " ('strangely', 1): 47,\n",
       " ('isle', 1): 13,\n",
       " ('man', 1): 1820,\n",
       " ('menaced', 1): 7,\n",
       " ('fierce', 1): 11,\n",
       " ('monster', 1): 633,\n",
       " ('assembled', 1): 25,\n",
       " ('blue', 1): 169,\n",
       " ('peter', 1): 270,\n",
       " ('episode', 1): 723,\n",
       " ('new', 1): 1355,\n",
       " ('teacher', 1): 225,\n",
       " ('must', 1): 1171,\n",
       " ('save', 1): 622,\n",
       " ('though', 1): 1646,\n",
       " ('oh', 1): 796,\n",
       " ('caresbr', 1): 7,\n",
       " ('br', 1): 23633,\n",
       " ('ill', 1): 511,\n",
       " ('start', 1): 1303,\n",
       " ('positive', 1): 265,\n",
       " ('nice', 1): 665,\n",
       " ('shot', 1): 1295,\n",
       " ('eastenders', 1): 23,\n",
       " ('gal', 1): 36,\n",
       " ('samantha', 1): 29,\n",
       " ('janus', 1): 8,\n",
       " ('obligatory', 1): 45,\n",
       " ('shower', 1): 86,\n",
       " ('scene', 1): 4532,\n",
       " ('best', 1): 1663,\n",
       " ('mate', 1): 81,\n",
       " ('katy', 1): 18,\n",
       " ('lawrence', 1): 50,\n",
       " ('bit', 1): 1161,\n",
       " ('side', 1): 477,\n",
       " ('trivia', 1): 28,\n",
       " ('hired', 1): 88,\n",
       " ('arrived', 1): 32,\n",
       " ('audition', 1): 49,\n",
       " ('sister', 1): 248,\n",
       " ('moral', 1): 145,\n",
       " ('support', 1): 118,\n",
       " ('sibling', 1): 34,\n",
       " ('landing', 1): 62,\n",
       " ('part', 1): 1961,\n",
       " ('joy', 1): 57,\n",
       " ('picked', 1): 184,\n",
       " ('obscurity', 1): 12,\n",
       " ('flash', 1): 103,\n",
       " ('pert', 1): 4,\n",
       " ('buttock', 1): 7,\n",
       " ('meaningless', 1): 58,\n",
       " ('titillation', 1): 13,\n",
       " ('getting', 1): 716,\n",
       " ('killed', 1): 532,\n",
       " ('30', 1): 300,\n",
       " ('minute', 1): 1989,\n",
       " ('trouble', 1): 262,\n",
       " ('latest', 1): 100,\n",
       " ('credited', 1): 28,\n",
       " ('role', 1): 1279,\n",
       " ('probationary', 1): 3,\n",
       " ('nurse', 1): 72,\n",
       " ('5', 1): 481,\n",
       " ('atonement', 1): 5,\n",
       " ('wonder', 1): 533,\n",
       " ('snuck', 1): 5,\n",
       " ('keira', 1): 6,\n",
       " ('knightly', 1): 11,\n",
       " ('extra', 1): 188,\n",
       " ('star', 1): 1259,\n",
       " ('allowed', 1): 148,\n",
       " ('mix', 1): 122,\n",
       " ('go', 1): 2992,\n",
       " ('wrongbr', 1): 38,\n",
       " ('give', 1): 1910,\n",
       " ('hint', 1): 106,\n",
       " ('british', 1): 245,\n",
       " ('member', 1): 327,\n",
       " ('asked', 1): 162,\n",
       " ('speak', 1): 223,\n",
       " ('american', 1): 890,\n",
       " ('accent', 1): 344,\n",
       " ('doomed', 1): 58,\n",
       " ('massmarketing', 1): 3,\n",
       " ('person', 1): 741,\n",
       " ('manage', 1): 114,\n",
       " ('bmovie', 1): 113,\n",
       " ('veteran', 1): 67,\n",
       " ('usa', 1): 55,\n",
       " ('native', 1): 149,\n",
       " ('todd', 1): 37,\n",
       " ('jensen', 1): 3,\n",
       " ('know', 1): 3004,\n",
       " ('wage', 1): 10,\n",
       " ('slip', 1): 38,\n",
       " ('itll', 1): 56,\n",
       " ('cover', 1): 338,\n",
       " ('lunch', 1): 19,\n",
       " ('bus', 1): 68,\n",
       " ('ride', 1): 138,\n",
       " ('home', 1): 584,\n",
       " ('aint', 1): 83,\n",
       " ('starring', 1): 156,\n",
       " ('trillion', 1): 3,\n",
       " ('dollar', 1): 178,\n",
       " ('budget', 1): 857,\n",
       " ('premiere', 1): 35,\n",
       " ('attended', 1): 22,\n",
       " ('load', 1): 106,\n",
       " ('family', 1): 863,\n",
       " ('fourth', 1): 46,\n",
       " ('assistant', 1): 75,\n",
       " ('provokes', 1): 8,\n",
       " ('gale', 1): 10,\n",
       " ('laughter', 1): 75,\n",
       " ('stickyback', 1): 3,\n",
       " ('tape', 1): 117,\n",
       " ('rampage', 1): 29,\n",
       " ('sewer', 1): 16,\n",
       " ('dawn', 1): 74,\n",
       " ('isnt', 1): 1520,\n",
       " ('exactly', 1): 408,\n",
       " ('alien', 1): 455,\n",
       " ('critter', 1): 56,\n",
       " ('iv', 1): 29,\n",
       " ('come', 1): 2150,\n",
       " ('think', 1): 2988,\n",
       " ('next', 1): 689,\n",
       " ('life', 1): 2021,\n",
       " ('im', 1): 2213,\n",
       " ('buddhist', 1): 6,\n",
       " ('see', 1): 4316,\n",
       " ('perhaps', 1): 653,\n",
       " ('youll', 1): 505,\n",
       " ('selective', 1): 15,\n",
       " ('debut', 1): 70,\n",
       " ('feature', 1): 561,\n",
       " ('impulsively', 1): 5,\n",
       " ('jumping', 1): 40,\n",
       " ('pile', 1): 110,\n",
       " ('crap', 1): 624,\n",
       " ('head', 1): 816,\n",
       " ('way', 1): 3205,\n",
       " ('flashing', 1): 25,\n",
       " ('skin', 1): 74,\n",
       " ('guarantee', 1): 48,\n",
       " ('long', 1): 1242,\n",
       " ('lasting', 1): 43,\n",
       " ('success', 1): 202,\n",
       " ('unless', 1): 390,\n",
       " ('sylvester', 1): 15,\n",
       " ('stallone', 1): 36,\n",
       " ('rocky', 1): 25,\n",
       " ('upbr', 1): 66,\n",
       " ('intent', 1): 61,\n",
       " ('purpose', 1): 278,\n",
       " ('010', 1): 30,\n",
       " ('ive', 1): 1345,\n",
       " ('ever', 1): 2483,\n",
       " ('seen', 1): 2593,\n",
       " ('however', 1): 1327,\n",
       " ('sheer', 1): 123,\n",
       " ('unintentional', 1): 69,\n",
       " ('laugh', 1): 924,\n",
       " ('pure', 1): 199,\n",
       " ('camp', 1): 183,\n",
       " ('value', 1): 468,\n",
       " ('1', 1): 668,\n",
       " ('done', 1): 1171,\n",
       " ('okay', 1): 382,\n",
       " ('hippy', 1): 15,\n",
       " ('probably', 1): 1228,\n",
       " ('wondering', 1): 167,\n",
       " ('education', 1): 38,\n",
       " ('informative', 1): 11,\n",
       " ('show', 1): 2917,\n",
       " ('barney', 1): 60,\n",
       " ('lot', 1): 1863,\n",
       " ('hate', 1): 379,\n",
       " ('reasonsbr', 1): 10,\n",
       " ('teach', 1): 69,\n",
       " ('personality', 1): 149,\n",
       " ('individualism', 1): 2,\n",
       " ('immoral', 1): 13,\n",
       " ('everyone', 1): 786,\n",
       " ('dress', 1): 63,\n",
       " ('alike', 1): 26,\n",
       " ('talk', 1): 393,\n",
       " ('act', 1): 752,\n",
       " ('dance', 1): 224,\n",
       " ('called', 1): 553,\n",
       " ('individual', 1): 93,\n",
       " ('kid', 1): 1135,\n",
       " ('tell', 1): 979,\n",
       " ('planet', 1): 170,\n",
       " ('wan', 1): 81,\n",
       " ('na', 1): 179,\n",
       " ('2', 1): 1153,\n",
       " ('stranger', 1): 81,\n",
       " ('friendyou', 1): 1,\n",
       " ('havent', 1): 296,\n",
       " ('met', 1): 105,\n",
       " ('seemingly', 1): 146,\n",
       " ('harmless', 1): 32,\n",
       " ('producer', 1): 432,\n",
       " ('soonfound', 1): 1,\n",
       " ('also', 1): 2942,\n",
       " ('extremely', 1): 493,\n",
       " ('dangerous', 1): 85,\n",
       " ('fact', 1): 1532,\n",
       " ('barneylovers', 1): 1,\n",
       " ('across', 1): 421,\n",
       " ('u', 1): 1269,\n",
       " ('fell', 1): 181,\n",
       " ('victim', 1): 323,\n",
       " ('pedophile', 1): 9,\n",
       " ('friendly', 1): 35,\n",
       " ('message', 1): 327,\n",
       " ('lure', 1): 29,\n",
       " ('away', 1): 1065,\n",
       " ('parent', 1): 265,\n",
       " ('pulled', 1): 97,\n",
       " ('damage', 1): 57,\n",
       " ('mistake', 1): 286,\n",
       " ('programming', 1): 22,\n",
       " ('clearly', 1): 365,\n",
       " ('need', 1): 1095,\n",
       " ('watch', 1): 2863,\n",
       " ('television', 1): 330,\n",
       " ('childrenbr', 1): 17,\n",
       " ('3', 1): 721,\n",
       " ('happy', 1): 257,\n",
       " ('bad', 1): 5756,\n",
       " ('seems', 1): 1615,\n",
       " ('emotion', 1): 236,\n",
       " ('happiness', 1): 24,\n",
       " ('matter', 1): 535,\n",
       " ('situation', 1): 403,\n",
       " ('mad', 1): 191,\n",
       " ('sad', 1): 388,\n",
       " ('reason', 1): 1375,\n",
       " ('may', 1): 1152,\n",
       " ('mommy', 1): 9,\n",
       " ('daddy', 1): 62,\n",
       " ('differently', 1): 32,\n",
       " ('allbr', 1): 105,\n",
       " ('4', 1): 460,\n",
       " ('magic', 1): 129,\n",
       " ('solves', 1): 8,\n",
       " ('everything', 1): 969,\n",
       " ('every', 1): 1561,\n",
       " ('problem', 1): 1044,\n",
       " ('solved', 1): 19,\n",
       " ('least', 1): 1566,\n",
       " ('fraggle', 1): 1,\n",
       " ('rock', 1): 298,\n",
       " ('backfire', 1): 7,\n",
       " ('solve', 1): 54,\n",
       " ('course', 1): 853,\n",
       " ('two', 1): 2441,\n",
       " ('fantasy', 1): 149,\n",
       " ('reality', 1): 263,\n",
       " ('might', 1): 1286,\n",
       " ('relative', 1): 61,\n",
       " ('use', 1): 738,\n",
       " ('yet', 1): 891,\n",
       " ('weird', 1): 255,\n",
       " ('boner', 1): 1,\n",
       " ('againbr', 1): 67,\n",
       " ('distinction', 1): 15,\n",
       " ('stealing', 1): 55,\n",
       " ('sharing', 1): 11,\n",
       " ('specifically', 1): 33,\n",
       " ('said', 1): 995,\n",
       " ('mind', 1): 799,\n",
       " ('learn', 1): 275,\n",
       " ('want', 1): 2069,\n",
       " ('something', 1): 2309,\n",
       " ('perfectly', 1): 112,\n",
       " ('acceptable', 1): 73,\n",
       " ('preschooler', 1): 1,\n",
       " ('authority', 1): 48,\n",
       " ('figure', 1): 360,\n",
       " ('thembr', 1): 133,\n",
       " ('6', 1): 167,\n",
       " ('thing', 1): 3642,\n",
       " ('whenever', 1): 116,\n",
       " ('whatever', 1): 331,\n",
       " ('sent', 1): 103,\n",
       " ('dont', 1): 4200,\n",
       " ('work', 1): 1864,\n",
       " ('solution', 1): 41,\n",
       " ('wouldnt', 1): 528,\n",
       " ('anyway', 1): 469,\n",
       " ('stop', 1): 538,\n",
       " ('thinking', 1): 570,\n",
       " ('dependent', 1): 7,\n",
       " ('object', 1): 79,\n",
       " ('shoe', 1): 69,\n",
       " ('food', 1): 130,\n",
       " ('computer', 1): 274,\n",
       " ('exercise', 1): 64,\n",
       " ('machine', 1): 154,\n",
       " ('marketer', 1): 4,\n",
       " ('preschoolersbr', 1): 1,\n",
       " ('7', 1): 118,\n",
       " ('cheating', 1): 43,\n",
       " ('involved', 1): 422,\n",
       " ('contest', 1): 50,\n",
       " ('carry', 1): 198,\n",
       " ('peanut', 1): 9,\n",
       " ('spoon', 1): 11,\n",
       " ('without', 1): 1268,\n",
       " ('dropping', 1): 33,\n",
       " ('butter', 1): 11,\n",
       " ('win', 1): 203,\n",
       " ('rewarded', 1): 16,\n",
       " ('creative', 1): 133,\n",
       " ('bent', 1): 28,\n",
       " ('rule', 1): 125,\n",
       " ('changed', 1): 178,\n",
       " ('game', 1): 579,\n",
       " ('people', 1): 3682,\n",
       " ('real', 1): 1628,\n",
       " ('often', 1): 500,\n",
       " ('disqualified', 1): 1,\n",
       " ('worse', 1): 960,\n",
       " ('severely', 1): 36,\n",
       " ('disliked', 1): 55,\n",
       " ('competitor', 1): 12,\n",
       " ('played', 1): 805,\n",
       " ('rulesbr', 1): 3,\n",
       " ('8', 1): 91,\n",
       " ('eat', 1): 127,\n",
       " ('anything', 1): 1463,\n",
       " ('else', 1): 944,\n",
       " ('besides', 1): 186,\n",
       " ('cake', 1): 41,\n",
       " ('cooky', 1): 8,\n",
       " ('candy', 1): 97,\n",
       " ('ton', 1): 70,\n",
       " ('junk', 1): 134,\n",
       " ('healthy', 1): 30,\n",
       " ('despite', 1): 515,\n",
       " ('barneys', 1): 6,\n",
       " ('health', 1): 21,\n",
       " ('song', 1): 594,\n",
       " ('eats', 1): 25,\n",
       " ('many', 1): 2348,\n",
       " ('obese', 1): 8,\n",
       " ('america', 1): 249,\n",
       " ('europebr', 1): 7,\n",
       " ('finallybr', 1): 2,\n",
       " ('solving', 1): 16,\n",
       " ('resort', 1): 44,\n",
       " ('instead', 1): 1104,\n",
       " ('decided', 1): 371,\n",
       " ('method', 1): 85,\n",
       " ('b', 1): 334,\n",
       " ('took', 1): 451,\n",
       " ('money', 1): 1218,\n",
       " ('blatant', 1): 56,\n",
       " ('sellout', 1): 7,\n",
       " ('little', 1): 2320,\n",
       " ('lyon', 1): 4,\n",
       " ('group', 1): 503,\n",
       " ('care', 1): 686,\n",
       " ('rant', 1): 34,\n",
       " ('worthy', 1): 103,\n",
       " ('four', 1): 319,\n",
       " ('rated', 1): 159,\n",
       " ('gave', 1): 521,\n",
       " ('86', 1): 14,\n",
       " ('always', 1): 933,\n",
       " ('hour', 1): 959,\n",
       " ('engaging', 1): 64,\n",
       " ('enough', 1): 1553,\n",
       " ('sit', 1): 345,\n",
       " ('big', 1): 1308,\n",
       " ('alligator', 1): 13,\n",
       " ('river', 1): 105,\n",
       " ('title', 1): 720,\n",
       " ('call', 1): 593,\n",
       " ('better', 1): 2630,\n",
       " ('average', 1): 325,\n",
       " ('nature', 1): 210,\n",
       " ('strike', 1): 92,\n",
       " ('moviebr', 1): 416,\n",
       " ('tourist', 1): 35,\n",
       " ('southeast', 1): 1,\n",
       " ('asia', 1): 30,\n",
       " ('employ', 1): 34,\n",
       " ('trying', 1): 1279,\n",
       " ('manipulate', 1): 10,\n",
       " ('mother', 1): 536,\n",
       " ('seeking', 1): 34,\n",
       " ('revenge', 1): 161,\n",
       " ('form', 1): 313,\n",
       " ('god', 1): 645,\n",
       " ('kroona', 1): 1,\n",
       " ('giant', 1): 203,\n",
       " ('creature', 1): 323,\n",
       " ('main', 1): 990,\n",
       " ('photographer', 1): 45,\n",
       " ('staff', 1): 51,\n",
       " ('worry', 1): 81,\n",
       " ('rubbed', 1): 12,\n",
       " ('wrong', 1): 900,\n",
       " ('toobr', 1): 36,\n",
       " ('welldone', 1): 16,\n",
       " ('adventurehorror', 1): 1,\n",
       " ('story', 1): 4155,\n",
       " ('musical', 1): 248,\n",
       " ('score', 1): 344,\n",
       " ('direction', 1): 633,\n",
       " ('attraction', 1): 55,\n",
       " ('fake', 1): 285,\n",
       " ('closeup', 1): 91,\n",
       " ('jaw', 1): 62,\n",
       " ('underwater', 1): 28,\n",
       " ('faraway', 1): 6,\n",
       " ('painfully', 1): 115,\n",
       " ('obvious', 1): 505,\n",
       " ('dealing', 1): 81,\n",
       " ('squeakytoy', 1): 1,\n",
       " ('zoo', 1): 18,\n",
       " ('souvenir', 1): 9,\n",
       " ('shop', 1): 103,\n",
       " ('believable', 1): 223,\n",
       " ('authenticbr', 1): 1,\n",
       " ('nonstop', 1): 36,\n",
       " ('thrill', 1): 86,\n",
       " ('produced', 1): 238,\n",
       " ('given', 1): 772,\n",
       " ('mention', 1): 396,\n",
       " ('high', 1): 717,\n",
       " ('body', 1): 596,\n",
       " ('count', 1): 159,\n",
       " ('scenery', 1): 181,\n",
       " ('par', 1): 80,\n",
       " ('expecting', 1): 266,\n",
       " ('eh', 1): 36,\n",
       " ('recent', 1): 202,\n",
       " ('counterpart', 1): 21,\n",
       " ('primeival', 1): 1,\n",
       " ('nothing', 1): 2303,\n",
       " ('compared', 1): 195,\n",
       " ('remember', 1): 579,\n",
       " ('return', 1): 283,\n",
       " ('seven', 1): 129,\n",
       " ('action', 1): 1289,\n",
       " ('elmer', 1): 4,\n",
       " ('bernstein', 1): 2,\n",
       " ('rousing', 1): 10,\n",
       " ('nevertheless', 1): 42,\n",
       " ('boring', 1): 1116,\n",
       " ('fails', 1): 341,\n",
       " ('involve', 1): 48,\n",
       " ('emotionally', 1): 68,\n",
       " ('mcqueens', 1): 2,\n",
       " ('absence', 1): 44,\n",
       " ('impression', 1): 183,\n",
       " ('different', 1): 667,\n",
       " ('littleknown', 1): 2,\n",
       " ('actor', 1): 2705,\n",
       " ('odd', 1): 210,\n",
       " ('developed', 1): 123,\n",
       " ('connect', 1): 51,\n",
       " ('hardly', 1): 297,\n",
       " ('die', 1): 356,\n",
       " ('sequel', 1): 465,\n",
       " ('passable', 1): 39,\n",
       " ('poor', 1): 1160,\n",
       " ('imitation', 1): 65,\n",
       " ('original', 1): 1509,\n",
       " ('ok', 1): 600,\n",
       " ('suck', 1): 361,\n",
       " ('examine', 1): 11,\n",
       " ('proposition', 1): 5,\n",
       " ('capable', 1): 91,\n",
       " ('transforming', 1): 11,\n",
       " ('energy', 1): 105,\n",
       " ('storing', 1): 1,\n",
       " ('transporting', 1): 7,\n",
       " ('reasembling', 1): 1,\n",
       " ('intriguing', 1): 99,\n",
       " ('thats', 1): 1808,\n",
       " ('far', 1): 1162,\n",
       " ('premise', 1): 338,\n",
       " ('delving', 1): 2,\n",
       " ('happen', 1): 423,\n",
       " ('kind', 1): 1385,\n",
       " ('break', 1): 370,\n",
       " ('damn', 1): 162,\n",
       " ('living', 1): 343,\n",
       " ('responsibilty', 1): 1,\n",
       " ('power', 1): 437,\n",
       " ('constant', 1): 118,\n",
       " ('temptation', 1): 14,\n",
       " ('ie', 1): 114,\n",
       " ('invisible', 1): 61,\n",
       " ('lembach', 1): 8,\n",
       " ('leave', 1): 441,\n",
       " ('doctor', 1): 313,\n",
       " ('jerryrigs', 1): 1,\n",
       " ('transport', 1): 6,\n",
       " ('goofed', 1): 1,\n",
       " ('dumb', 1): 425,\n",
       " ('secretary', 1): 45,\n",
       " ('duh', 1): 18,\n",
       " ('happened', 1): 453,\n",
       " ('hadnt', 1): 122,\n",
       " ('roaming', 1): 13,\n",
       " ('country', 1): 270,\n",
       " ('killing', 1): 405,\n",
       " ('experiment', 1): 144,\n",
       " ('failed', 1): 265,\n",
       " ('wah', 1): 7,\n",
       " ('throw', 1): 233,\n",
       " ('dry', 1): 102,\n",
       " ('relationship', 1): 293,\n",
       " ('semicompetent', 1): 3,\n",
       " ('professor', 1): 86,\n",
       " ('assist', 1): 11,\n",
       " ('loving', 1): 58,\n",
       " ('session', 1): 40,\n",
       " ('halfhearted', 1): 11,\n",
       " ('find', 1): 1799,\n",
       " ('kill', 1): 881,\n",
       " ('london', 1): 114,\n",
       " ('headed', 1): 20,\n",
       " ('breaking', 1): 51,\n",
       " ('would', 1): 5734,\n",
       " ('left', 1): 924,\n",
       " ('tried', 1): 389,\n",
       " ('honest', 1): 183,\n",
       " ('effort', 1): 511,\n",
       " ('broke', 1): 64,\n",
       " ('making', 1): 1115,\n",
       " ('heartwarming', 1): 7,\n",
       " ('tale', 1): 230,\n",
       " ('hope', 1): 614,\n",
       " ('endure', 1): 42,\n",
       " ('awful', 1): 1188,\n",
       " ('cough', 1): 10,\n",
       " ('razzie', 1): 19,\n",
       " ('award', 1): 162,\n",
       " ('coughbr', 1): 1,\n",
       " ('unfunny', 1): 183,\n",
       " ('predictable', 1): 475,\n",
       " ('inane', 1): 76,\n",
       " ('watching', 1): 2041,\n",
       " ('felt', 1): 622,\n",
       " ('psychology', 1): 22,\n",
       " ('determine', 1): 14,\n",
       " ('low', 1): 758,\n",
       " ('standard', 1): 333,\n",
       " ('complained', 1): 14,\n",
       " ('requested', 1): 4,\n",
       " ('informed', 1): 24,\n",
       " ('watched', 1): 915,\n",
       " ('entitled', 1): 21,\n",
       " ('reimbursement', 1): 1,\n",
       " ('told', 1): 344,\n",
       " ('manager', 1): 39,\n",
       " ('gotten', 1): 113,\n",
       " ('refund', 1): 19,\n",
       " ('thoughbr', 1): 31,\n",
       " ('summary', 1): 82,\n",
       " ('basic', 1): 245,\n",
       " ('midget', 1): 26,\n",
       " ('thief', 1): 73,\n",
       " ('pose', 1): 39,\n",
       " ('baby', 1): 262,\n",
       " ('elude', 1): 1,\n",
       " ('police', 1): 375,\n",
       " ('underneath', 1): 22,\n",
       " ('clever', 1): 175,\n",
       " ('outline', 1): 35,\n",
       " ('lie', 1): 147,\n",
       " ('repertoire', 1): 11,\n",
       " ('fresh', 1): 101,\n",
       " ('hilarious', 1): 263,\n",
       " ('skit', 1): 80,\n",
       " ('notbr', 1): 48,\n",
       " ('ask', 1): 284,\n",
       " ('following', 1): 206,\n",
       " ('hit', 1): 437,\n",
       " ('pan', 1): 31,\n",
       " ('fart', 1): 22,\n",
       " ('joke', 1): 764,\n",
       " ('posing', 1): 31,\n",
       " ('threatened', 1): 24,\n",
       " ('thermometer', 1): 2,\n",
       " ('anus', 1): 3,\n",
       " ('tired', 1): 234,\n",
       " ('racial', 1): 39,\n",
       " ('goo', 1): 22,\n",
       " ('gaa', 1): 2,\n",
       " ('droolbr', 1): 1,\n",
       " ('answered', 1): 19,\n",
       " ('definitely', 1): 430,\n",
       " ('although', 1): 775,\n",
       " ('billed', 1): 22,\n",
       " ('worst', 1): 1882,\n",
       " ('decade', 1): 141,\n",
       " ('worsesomewhere', 1): 1,\n",
       " ('cant', 1): 1840,\n",
       " ('sure', 1): 1094,\n",
       " ('review', 1): 731,\n",
       " ('indicate', 1): 22,\n",
       " ('bias', 1): 22,\n",
       " ('reviewer', 1): 201,\n",
       " ('taken', 1): 352,\n",
       " ('seriously', 1): 511,\n",
       " ('lowbrow', 1): 19,\n",
       " ('intended', 1): 155,\n",
       " ('le', 1): 766,\n",
       " ('intelligent', 1): 141,\n",
       " ('audience', 1): 1065,\n",
       " ('conscience', 1): 17,\n",
       " ('recommend', 1): 536,\n",
       " ('anyone', 1): 1113,\n",
       " ('funnybr', 1): 78,\n",
       " ('respect', 1): 215,\n",
       " ('rating', 1): 470,\n",
       " ('ridiculously', 1): 95,\n",
       " ('bring', 1): 334,\n",
       " ('reasonable', 1): 62,\n",
       " ('sat', 1): 144,\n",
       " ('tagging', 1): 20,\n",
       " ('shoplifting', 1): 9,\n",
       " ('dialog', 1): 494,\n",
       " ('finally', 1): 598,\n",
       " ('tagger', 1): 2,\n",
       " ('kissed', 1): 13,\n",
       " ('screening', 1): 61,\n",
       " ('impressed', 1): 105,\n",
       " ('pretentious', 1): 165,\n",
       " ('filmmaking', 1): 167,\n",
       " ('previous', 1): 205,\n",
       " ('selfrighteous', 1): 11,\n",
       " ('defense', 1): 37,\n",
       " ('manboy', 1): 2,\n",
       " ('love', 1): 1723,\n",
       " ('interesting', 1): 1298,\n",
       " ('graffiti', 1): 22,\n",
       " ('artist', 1): 115,\n",
       " ('oliver', 1): 49,\n",
       " ('stone', 1): 135,\n",
       " ('brian', 1): 53,\n",
       " ('depalma', 1): 2,\n",
       " ('al', 1): 92,\n",
       " ('pacino', 1): 47,\n",
       " ('michelle', 1): 34,\n",
       " ('pfiefer', 1): 2,\n",
       " ('monumental', 1): 6,\n",
       " ('cinematic', 1): 166,\n",
       " ('garbage', 1): 312,\n",
       " ('rich', 1): 203,\n",
       " ('successful', 1): 195,\n",
       " ('wasting', 1): 127,\n",
       " ('forgettable', 1): 131,\n",
       " ('trite', 1): 74,\n",
       " ('pathetic', 1): 321,\n",
       " ('represents', 1): 41,\n",
       " ('hollywoodbr', 1): 13,\n",
       " ('based', 1): 489,\n",
       " ('true', 1): 633,\n",
       " ('news', 1): 132,\n",
       " ('bite', 1): 58,\n",
       " ('today', 1): 282,\n",
       " ('departs', 1): 2,\n",
       " ('cuban', 1): 21,\n",
       " ('refugee', 1): 19,\n",
       " ('going', 1): 1902,\n",
       " ('drug', 1): 284,\n",
       " ('subculture', 1): 8,\n",
       " ('cocaine', 1): 25,\n",
       " ('cuba', 1): 33,\n",
       " ('believe', 1): 1097,\n",
       " ('single', 1): 380,\n",
       " ('totally', 1): 630,\n",
       " ('antonios', 1): 2,\n",
       " ('poster', 1): 86,\n",
       " ('midwest', 1): 6,\n",
       " ('dick', 1): 74,\n",
       " ('van', 1): 256,\n",
       " ('dyke', 1): 15,\n",
       " ('miami', 1): 15,\n",
       " ('la', 1): 276,\n",
       " ('transposed', 1): 4,\n",
       " ('florida', 1): 30,\n",
       " ('afterall', 1): 7,\n",
       " ('palm', 1): 20,\n",
       " ('romance', 1): 182,\n",
       " ('novel', 1): 424,\n",
       " ('pfeiffer', 1): 6,\n",
       " ('getgo', 1): 13,\n",
       " ('shred', 1): 24,\n",
       " ('possibility', 1): 80,\n",
       " ('issue', 1): 240,\n",
       " ('obsession', 1): 45,\n",
       " ('addiction', 1): 26,\n",
       " ('mentioned', 1): 250,\n",
       " ('behavior', 1): 102,\n",
       " ('line', 1): 1397,\n",
       " ('coke', 1): 21,\n",
       " ('drink', 1): 122,\n",
       " ('water', 1): 222,\n",
       " ('admittedly', 1): 69,\n",
       " ('terriblebr', 1): 24,\n",
       " ('music', 1): 968,\n",
       " ('disgusting', 1): 136,\n",
       " ('sound', 1): 897,\n",
       " ('latin', 1): 21,\n",
       " ('elevator', 1): 38,\n",
       " ('welk', 1): 3,\n",
       " ('heard', 1): 438,\n",
       " ('polka', 1): 2,\n",
       " ('shoddy', 1): 58,\n",
       " ('movement', 1): 104,\n",
       " ('crane', 1): 7,\n",
       " ('effective', 1): 106,\n",
       " ('photography', 1): 147,\n",
       " ('excessive', 1): 31,\n",
       " ('bleached', 1): 3,\n",
       " ('number', 1): 448,\n",
       " ('spot', 1): 180,\n",
       " ('carried', 1): 71,\n",
       " ('warehouse', 1): 27,\n",
       " ('writing', 1): 593,\n",
       " ('appalling', 1): 84,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this cell to get an idea about the corpus of words and their occurrence along with labels. \n",
    "## In this, we are computing the frequency of occurrence of word given that a review is 'positive'.\n",
    "## Similarly, we also compute the frequence of occurence of word given that a review is 'negative'.\n",
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759c24bc",
   "metadata": {
    "id": "759c24bc"
   },
   "source": [
    "## Q4. Training the Naive Bayes Model: (20 points)\n",
    "\n",
    "Now we are in the training phase of the Naive Bayes algorithm. In this cell, take a look at the ways to calculate the log likelihood and log prior values as these are important for testing in the next few cells. \n",
    "\n",
    "Also calculate the frequency of occurrence of words where the output is negative. In the same way, calculate the word frequency count using the above functions in order to compute the log likelihood.\n",
    "\n",
    "Return the logprior and loglikelihood output by the model from this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f280e3",
   "metadata": {
    "id": "a7f280e3"
   },
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of reviews\n",
    "        train_y: a list of labels correponding to the reviews (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set(list(zip(*freqs))[0])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
    "    num_pos = num_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            num_pos = num_pos + freqs[pair]\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            num_neg = num_neg + freqs[pair]\n",
    "\n",
    "    # Calculate num_doc, the number of documents\n",
    "    num_doc = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents \n",
    "    pos_num_docs = train_y.value_counts()[0]\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    neg_num_docs = train_y.value_counts()[1]\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(neg_num_docs/pos_num_docs)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = find_occurrence(freqs,word,0)\n",
    "        freq_neg = find_occurrence(freqs,word,1)\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (1 + freq_pos) / ((1*V) + num_pos)\n",
    "        p_w_neg = (1 + freq_neg) / ((1*V) + num_neg)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_neg/p_w_pos)\n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1561d892",
   "metadata": {
    "id": "1561d892",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "91992\n"
     ]
    }
   ],
   "source": [
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52e087dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# storing loglikelihood & logprior\n",
    "with open('logprior.pkl', 'wb') as f:\n",
    "    pickle.dump( logprior, f)\n",
    "with open('loglikelihood.pkl', 'wb') as f:\n",
    "    pickle.dump( loglikelihood, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9c882",
   "metadata": {
    "id": "19d9c882"
   },
   "source": [
    "### Expected Output \n",
    "\n",
    "0.0 <br>\n",
    "91425"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b51303",
   "metadata": {
    "id": "78b51303"
   },
   "source": [
    "## Q5. Implementing Naive Bayes Predict Function: (10 points)\n",
    "\n",
    "It is now time to make our prediction as to whether a given review is negative or positive respectively. \n",
    "\n",
    "After adding the log likelihood values, ensure that the output is 1 (negative) if the sum of the log likelihood value is greater than 0 and 0 (positive) if the sum of the log likelihood is less than or equal to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b692c2f9",
   "metadata": {
    "id": "b692c2f9"
   },
   "outputs": [],
   "source": [
    "# TASK 4 CELL\n",
    "\n",
    "def naive_bayes_predict(review, logprior, loglikelihood):\n",
    "    '''\n",
    "    Params:\n",
    "        review: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Return:\n",
    "        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    \n",
    "      # process the review to get a list of words\n",
    "    word_l = clean_review(review)\n",
    "\n",
    "    # initialize probability to zero\n",
    "    total_prob = 0\n",
    "\n",
    "    # add the logprior\n",
    "    total_prob = total_prob + logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            total_prob = total_prob + loglikelihood[word]\n",
    "\n",
    "\n",
    "    return 1 if total_prob>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b170333",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b170333",
    "outputId": "0cf6bc90-90e8-4dee-bf95-7eaf39dce147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1\n"
     ]
    }
   ],
   "source": [
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "\n",
    "# Experiment with your own review.\n",
    "my_review = \"I thought this series was going to be another fun, action series with some dynamic plots and great performances. I was wrong. While I like Jamie Denton, this show is hardly worth watching at all, unless you enjoy watching some people brutalized and the actions of the agents supposedly warranted under the theme of national security. The show is great propaganda for the current government, and spews out jingoism as though we talk that way every day. After a couple of episodes, it was boring the hell out of me, and I started watching reruns of House Invaders on BBCAmerica instead. Rather watch CSI and Without a Trace, without a doubt.\"\n",
    "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242708f",
   "metadata": {
    "id": "6242708f"
   },
   "source": [
    "### Expected Output :\n",
    "The expected output is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4eeb71",
   "metadata": {
    "id": "7c4eeb71"
   },
   "source": [
    "## Q6. Implementing Naive Bayes Test function: (10 points)\n",
    "\n",
    "In this function, implement the previous functions such as naive_bayes_predict to get the predictions for the test set. \n",
    "\n",
    "In addition to this, the function should return the total number of reviews that it correctly classified as 'positive' or 'negative'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66a511e7",
   "metadata": {
    "id": "66a511e7"
   },
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of reviews\n",
    "        test_y: the corresponding labels for the list of reviews\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
    "    \"\"\"\n",
    "    accuracy = 0  \n",
    "\n",
    "    \n",
    "    y_hats = []\n",
    "    for review in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(review, logprior, loglikelihood) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = np.mean(np.absolute(y_hats-test_y))\n",
    "\n",
    "    accuracy = 1 - error\n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9c5d9d",
   "metadata": {
    "id": "8a9c5d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00\n",
      "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00\n",
      "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00\n",
      "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n"
     ]
    }
   ],
   "source": [
    "# For grading purpose only\n",
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "\n",
    "# Run this cell to test your function\n",
    "\n",
    "for review in [\"If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\",\n",
    "                \"What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative direction, too. Some VERY faint echoes of Fargo here, but it just doesn't come off.\",\n",
    "                \"I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the romance between Joe and Jean keeps me on the edge of my seat, plus I still think Bryan Brown is the tops. Brilliant Film.\",\n",
    "                \"Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement value. About as unentertaining, uninstructive and just plain dull as a film can be.\"]:\n",
    "    p = naive_bayes_predict(review, logprior, loglikelihood)\n",
    "    print(f'{review[:100]} -> {p:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2ef98",
   "metadata": {
    "id": "43e2ef98"
   },
   "source": [
    "### Expected Output :\n",
    "\n",
    "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00 <br>\n",
    "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00<br>\n",
    "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00 <br>\n",
    "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "216fa97a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "216fa97a",
    "outputId": "9d1f21c7-b324-43c2-e841-269c0306cbb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to check the sentiment of your own review below\n",
    "my_review = 'The moview was very boring, I wanted to leave in the middle'\n",
    "naive_bayes_predict(my_review, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45e4f0",
   "metadata": {
    "id": "8a45e4f0"
   },
   "source": [
    "### Expected Output :\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mAIkM4aCC1H7",
   "metadata": {
    "id": "mAIkM4aCC1H7"
   },
   "source": [
    "# Q7. Evaluate the accuracy (10 Points)\n",
    "1. Split your data into training and test sets using random selection. Set the seed as parameter of the function so that user can select a different training and test set by changing seed.\n",
    "\n",
    "2. Calculate model paramters with training set.\n",
    "\n",
    "3. Print confusion matrix for training and test set.\n",
    "\n",
    "4. Examine False Positive and False Negative cases and provide reasoning why they get misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef8266",
   "metadata": {},
   "source": [
    "#### Q7.1) Split your data into training and test sets using random selection. Set the seed as parameter of the function so that user can select a different training and test set by changing seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d7cd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# using shuffle from sklearn to shuffle the dataset and also setting random seed \n",
    "\n",
    "df_shuffled = shuffle(df_upsampled, random_state=45)\n",
    "\n",
    "## Considering 10000 positive & negative data points\n",
    "negative_data_points_train = df_shuffled[df_shuffled['sentiment'] == 'negative'].iloc[:10000]\n",
    "positive_data_points_train = df_shuffled[df_shuffled['sentiment'] == 'positive'].iloc[:10000]\n",
    "\n",
    "## Considering the remaining data points for test\n",
    "negative_data_points_test = df_shuffled[df_shuffled['sentiment'] == 'negative'].iloc[10000:]\n",
    "positive_data_points_test = df_shuffled[df_shuffled['sentiment'] == 'positive'].iloc[10000:]\n",
    "\n",
    "## Concatenate the training positive and negative reviews\n",
    "X_train = pd.concat([negative_data_points_train['review'], positive_data_points_train['review']])\n",
    "## Concatenating the training positive and negative outputs\n",
    "y_train = pd.concat([negative_data_points_train['sentiment'], positive_data_points_train['sentiment']])\n",
    "\n",
    "## Concatenating the test positive and negative reviews\n",
    "X_test = pd.concat([negative_data_points_test['review'], positive_data_points_test['review']])\n",
    "## Concatenating the test positive and negative outputs\n",
    "y_test = pd.concat([negative_data_points_test['sentiment'], positive_data_points_test['sentiment']])\n",
    "\n",
    "output_map = {'positive': 0, 'negative': 1}\n",
    "y_train = y_train.map(output_map)\n",
    "y_test = y_test.map(output_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbacc1",
   "metadata": {},
   "source": [
    "#### 7.2)  Calculate model paramters with training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38790273",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_n = review_counter({}, X_train, y_train)\n",
    "\n",
    "# getting logprior and loglikihood and storing it in NB \n",
    "NB = train_naive_bayes(freqs_n, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "375a2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving logprior and logliklihood in local file (.pkl - pickle file )\n",
    "import pickle\n",
    "with open('NB.pickle', 'wb') as f:\n",
    "    pickle.dump(NB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a373709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " {'hammered': -0.7044877506823382,\n",
       "  'allblackcast': -0.7044877506823379,\n",
       "  'chandu': 0.9049501617517622,\n",
       "  'hadleys': -1.1099528587905023,\n",
       "  'toying': -0.2990226425741737,\n",
       "  'stillrelevant': 0.6818066104375526,\n",
       "  'levered': 0.6818066104375526,\n",
       "  'contemplation': -0.5991272350245117,\n",
       "  'buddybuddy': 0.3941245379857716,\n",
       "  'pooreras': -0.7044877506823379,\n",
       "  'rei': -1.1099528587905023,\n",
       "  'movietill': -0.7044877506823379,\n",
       "  'reverberating': -0.7044877506823379,\n",
       "  'obnoxious': 1.1307568304854556,\n",
       "  'wirework': -0.4168056782305571,\n",
       "  'heifitz': -0.7044877506823379,\n",
       "  'pharmacy': -1.1099528587905023,\n",
       "  'normalos': -0.7044877506823379,\n",
       "  '3d': 0.35638421000292464,\n",
       "  'venturing': -0.2990226425741737,\n",
       "  'rakoff': 0.6818066104375526,\n",
       "  'handcuffing': -0.7044877506823379,\n",
       "  'bet': 0.5403070481638531,\n",
       "  'workart': -0.7044877506823379,\n",
       "  'sophias': -0.011340570122392642,\n",
       "  'bioports': -0.7044877506823379,\n",
       "  'atrociously': 1.1926322342035431,\n",
       "  'hoskins': 0.8759626248785098,\n",
       "  'snobbish': -0.4633256938654498,\n",
       "  'worldongoing': -0.7044877506823379,\n",
       "  'miniplotsbr': 0.6818066104375526,\n",
       "  'seehear': -1.1099528587905023,\n",
       "  'cirinos': -0.7044877506823379,\n",
       "  'yesteryear': 0.32513166649882014,\n",
       "  'mamoru': -0.011340570122392868,\n",
       "  '134minute': -0.7044877506823379,\n",
       "  'treachs': 0.6818066104375526,\n",
       "  'fluegel': -0.7044877506823379,\n",
       "  'storiesby': 0.6818066104375526,\n",
       "  'flyover': 0.3941245379857716,\n",
       "  'acceleration': 0.6818066104375526,\n",
       "  'hued': -0.7044877506823379,\n",
       "  'iiascension': 1.0872717185457168,\n",
       "  'hioh': -0.7044877506823379,\n",
       "  'unhelpful': -1.620778482556493,\n",
       "  'charlies': -0.5503370708550798,\n",
       "  'nimione': -0.7044877506823379,\n",
       "  'fortnight': -0.7044877506823379,\n",
       "  'filmthe': -0.4168056782305571,\n",
       "  'birthplace': 0.21180298119181692,\n",
       "  'clarethe': -0.7044877506823379,\n",
       "  'outmy': 0.6818066104375524,\n",
       "  'lalala': -0.7044877506823379,\n",
       "  'hypnothised': -0.7044877506823379,\n",
       "  'nefer': -2.3139256631164384,\n",
       "  'bifff': -0.7044877506823379,\n",
       "  'orgyinabox': -0.7044877506823379,\n",
       "  'malay': -0.011340570122392868,\n",
       "  'befuddled': -1.3976349312422833,\n",
       "  'discredit': 1.6934075221160325,\n",
       "  'welleducated': 0.3941245379857716,\n",
       "  'cardinale': -0.7044877506823379,\n",
       "  'shortsbr': -0.7044877506823379,\n",
       "  'jun': 1.0872717185457168,\n",
       "  'fdfs': 0.6818066104375526,\n",
       "  'cellular': 1.0872717185457168,\n",
       "  'kotero': -0.7044877506823379,\n",
       "  'humiliated': -0.1544414137630661,\n",
       "  'funimations': -0.7044877506823379,\n",
       "  'powellpressburgers': -0.7044877506823379,\n",
       "  'kildares': -0.7044877506823379,\n",
       "  '1933s': -0.7044877506823379,\n",
       "  'olsenjoey': -0.7044877506823379,\n",
       "  'thus': -0.2133671979956798,\n",
       "  'oy': 1.7804188991056622,\n",
       "  'suntan': -0.7044877506823379,\n",
       "  'drudgerybr': 0.6818066104375526,\n",
       "  'moonshaped': 0.6818066104375526,\n",
       "  'beatened': -0.7044877506823379,\n",
       "  'sadler': -0.4168056782305571,\n",
       "  'obãlix': -1.1099528587905023,\n",
       "  'readi': -0.7044877506823379,\n",
       "  'forestcamouflage': 1.0872717185457168,\n",
       "  'greets': -1.2641035386177608,\n",
       "  'lebeau': -1.1099528587905023,\n",
       "  'careerand': -0.7044877506823379,\n",
       "  'trilling': 0.3941245379857716,\n",
       "  'islington': -0.011340570122392642,\n",
       "  'thank': -0.4525729020891882,\n",
       "  'monterone': -0.011340570122392642,\n",
       "  'comediesshe': 0.6818066104375526,\n",
       "  'bgrade': 1.241422398372975,\n",
       "  'upandcomers': 1.0872717185457168,\n",
       "  'auteuils': 0.6818066104375526,\n",
       "  'homemovie': 1.0872717185457168,\n",
       "  'gieldgud': -0.7044877506823379,\n",
       "  'fastfoodmainstream': -0.7044877506823379,\n",
       "  'leif': 0.27634150232938826,\n",
       "  'confidante': -0.23448412143660244,\n",
       "  'summa': -1.1099528587905023,\n",
       "  'humphery': -0.7044877506823379,\n",
       "  'barcode': 1.374953790997498,\n",
       "  'footmats': -0.7044877506823379,\n",
       "  'lilylivered': -1.1099528587905023,\n",
       "  'britten': -0.7044877506823379,\n",
       "  'rogerbr': 1.0872717185457168,\n",
       "  'darling': 0.045817843717555755,\n",
       "  'marketyou': -0.7044877506823379,\n",
       "  'schwarzenegger': 0.761849318111089,\n",
       "  'anniebr': 0.3941245379857716,\n",
       "  'bookie': 0.3941245379857716,\n",
       "  'snobbyaffluent': -0.7044877506823379,\n",
       "  'prem': -1.7605404249316516,\n",
       "  'emergesbr': -0.7044877506823379,\n",
       "  '1930the': -0.7044877506823379,\n",
       "  'landybourne': -0.7044877506823379,\n",
       "  'irvin': -0.14487196274691527,\n",
       "  'newlypregnant': -0.7044877506823379,\n",
       "  'indispensable': -1.3976349312422833,\n",
       "  'tiled': -0.7044877506823379,\n",
       "  'jean': -1.144439034861672,\n",
       "  'vividly': -1.168793358813436,\n",
       "  'radiation': 0.9919615387413923,\n",
       "  'acclamation': -1.1099528587905023,\n",
       "  'muffled': 1.9345695789329207,\n",
       "  'kwouks': 0.6818066104375526,\n",
       "  'lsd': 0.6818066104375524,\n",
       "  'profitbr': 0.6818066104375526,\n",
       "  'nondocumentary': 0.3941245379857716,\n",
       "  'selfinflicted': -0.7044877506823379,\n",
       "  'originalthere': 1.0872717185457168,\n",
       "  'mathematics': -1.620778482556493,\n",
       "  'foundas': -1.1099528587905023,\n",
       "  'supervillains': 1.0872717185457168,\n",
       "  'wirefu': 0.6818066104375526,\n",
       "  'didjust': -0.7044877506823379,\n",
       "  'urbibe': -0.7044877506823379,\n",
       "  'instead': 0.7125226656679997,\n",
       "  'katja': 0.6818066104375526,\n",
       "  'timewho': 0.6818066104375526,\n",
       "  'semicomplicated': -0.7044877506823379,\n",
       "  'spaniard': 1.5980973423117075,\n",
       "  'kidsuddenly': -0.7044877506823379,\n",
       "  'pretension': -0.442123486214847,\n",
       "  'glimpse': -0.541968821184563,\n",
       "  'greatlady': -0.7044877506823379,\n",
       "  'featurebr': -1.620778482556493,\n",
       "  'memorialized': -0.7044877506823379,\n",
       "  'lorussobr': -0.7044877506823379,\n",
       "  'kish': -0.7044877506823379,\n",
       "  'politicsespecially': -0.7044877506823379,\n",
       "  'comingofagestory': -0.7044877506823379,\n",
       "  'styalised': -0.7044877506823379,\n",
       "  'rohmers': 1.0872717185457168,\n",
       "  'demolished': -1.3976349312422833,\n",
       "  'barbarity': -0.7044877506823379,\n",
       "  'badguy': 1.5980973423117075,\n",
       "  'berlin': -1.2641035386177606,\n",
       "  'repaying': -0.7044877506823379,\n",
       "  'gauzy': 0.6818066104375526,\n",
       "  'historicaly': 1.0872717185457168,\n",
       "  'ledoyen': -1.1099528587905023,\n",
       "  'primarilly': -0.7044877506823379,\n",
       "  'peres': 1.5980973423117075,\n",
       "  'yearly': -0.011340570122392868,\n",
       "  'turistas': 0.3941245379857716,\n",
       "  'mst3ks': 1.0872717185457168,\n",
       "  'itknow': -0.7044877506823379,\n",
       "  'lostness': -0.7044877506823379,\n",
       "  'playswe': 0.6818066104375526,\n",
       "  'sluttish': -0.2990226425741737,\n",
       "  'aashok': -0.7044877506823379,\n",
       "  '1941br': 0.3941245379857716,\n",
       "  'forked': 0.6818066104375526,\n",
       "  'boston': -0.11312326443233511,\n",
       "  'selfregarding': 1.0872717185457168,\n",
       "  'convincinglybr': -0.9276313019965478,\n",
       "  'chanwook': -2.9017123280185575,\n",
       "  'wounded': -0.29164253527655115,\n",
       "  'oneact': 1.0872717185457168,\n",
       "  'starblazers': -0.7044877506823379,\n",
       "  'listens': -0.6303797785286162,\n",
       "  'fridayeastern': -0.7044877506823379,\n",
       "  'assuring': -0.7044877506823379,\n",
       "  'nakedsmoked': -0.7044877506823379,\n",
       "  'characterdr': -0.7044877506823379,\n",
       "  'frill': -0.2990226425741737,\n",
       "  '71202': -0.7044877506823379,\n",
       "  'sixpack': 1.5980973423117075,\n",
       "  'snakejumpsout': 1.0872717185457168,\n",
       "  'annabel': 1.5980973423117075,\n",
       "  'knocker': -0.4168056782305571,\n",
       "  'florescence': -0.7044877506823379,\n",
       "  'enjoyment': -0.19744284975625345,\n",
       "  'rapidity': -0.7044877506823379,\n",
       "  'casket': -0.34781280674360576,\n",
       "  'elaine': -0.7845304583558745,\n",
       "  'premade': -1.1099528587905023,\n",
       "  'distinct': -0.11399472418247611,\n",
       "  'qualitywell': 0.6818066104375526,\n",
       "  'suicidehe': 0.6818066104375526,\n",
       "  'exterminating': 0.27634150232938826,\n",
       "  'palace': -0.3596472643906084,\n",
       "  'kinskis': 0.4994850536435978,\n",
       "  'enhancedbr': -0.7044877506823379,\n",
       "  'tukurs': -0.7044877506823379,\n",
       "  'frontyard': -0.7044877506823379,\n",
       "  'kazurinsky': -0.7044877506823379,\n",
       "  'cyst': 0.6818066104375526,\n",
       "  'englishspeaking': -0.011340570122392868,\n",
       "  'today': -0.9542248915699955,\n",
       "  'sciencefictionstories': -0.7044877506823379,\n",
       "  'chiojo': -0.7044877506823379,\n",
       "  'religionbr': -1.1099528587905023,\n",
       "  'sorbonne': -1.5154179668986667,\n",
       "  'exampleall': 0.6818066104375526,\n",
       "  'ruffianly': -0.7044877506823379,\n",
       "  'kangwon': -1.3976349312422833,\n",
       "  'enchantingbr': -0.7044877506823379,\n",
       "  'bergen': -0.7734806221692895,\n",
       "  'willies1926is': -0.7044877506823379,\n",
       "  'bikerflicks': 0.6818066104375526,\n",
       "  'lonelinessand': -0.7044877506823379,\n",
       "  'devoured': -0.23448412143660244,\n",
       "  'grayt': -0.7044877506823379,\n",
       "  'mrrgvsholay': 1.0872717185457168,\n",
       "  'conceited': 0.6818066104375526,\n",
       "  'actressfinally': 1.0872717185457168,\n",
       "  'okulthe': 0.6818066104375526,\n",
       "  'radioevangelist': -0.7044877506823379,\n",
       "  'slayride': 0.6818066104375526,\n",
       "  'previewsbr': 1.374953790997498,\n",
       "  'halfbreed': 0.8359572902648108,\n",
       "  'tiptop': -0.011340570122392642,\n",
       "  'brokenwhat': -0.7044877506823379,\n",
       "  'linesyes': -0.7044877506823379,\n",
       "  'retroartdeconess': -0.7044877506823379,\n",
       "  'zslasher': 1.0872717185457168,\n",
       "  'ringerokay': 1.0872717185457168,\n",
       "  'divorcedand': 0.6818066104375526,\n",
       "  'mandrakis': 1.0872717185457168,\n",
       "  'jarvas': -1.620778482556493,\n",
       "  'hunted': 0.5592042883452201,\n",
       "  'thingunlike': 0.6818066104375526,\n",
       "  'â½br': 0.6818066104375526,\n",
       "  'okaying': -0.7044877506823379,\n",
       "  'ilva': -0.7044877506823379,\n",
       "  'censoredharry': -0.7044877506823379,\n",
       "  'unethical': 0.7771167902418773,\n",
       "  'celebrityart': -0.7044877506823379,\n",
       "  'protãgãe': -1.1099528587905023,\n",
       "  'overlaid': 0.9049501617517622,\n",
       "  'guysinobviousshoddyrubbersuits': -0.7044877506823379,\n",
       "  'sceneelisha': -0.7044877506823379,\n",
       "  'disappointingthis': 1.0872717185457168,\n",
       "  'lousinia': 1.0872717185457168,\n",
       "  'careering': -0.7044877506823379,\n",
       "  'espers': -0.7044877506823379,\n",
       "  'leonardo': -0.5709563580578154,\n",
       "  'kingpenned': -0.7044877506823379,\n",
       "  'explaina': -0.7044877506823379,\n",
       "  'piovanis': -0.7044877506823379,\n",
       "  'saigon': 0.27634150232938826,\n",
       "  'foiling': 0.3941245379857716,\n",
       "  'hollywoodrules': 1.0872717185457168,\n",
       "  'songsegad': 0.6818066104375526,\n",
       "  'ingeniously': -1.2641035386177608,\n",
       "  'bergmanwho': 0.6818066104375526,\n",
       "  'everthree': -0.7044877506823379,\n",
       "  'katherines': 0.3941245379857716,\n",
       "  'classicthe': 0.6818066104375526,\n",
       "  'retainer': -1.1099528587905023,\n",
       "  'meditative': -2.0907821118022287,\n",
       "  'addressing': -1.1099528587905023,\n",
       "  'bollmeister': 0.6818066104375526,\n",
       "  'winoswino': -0.7044877506823379,\n",
       "  'pokemon': -2.1215537704689824,\n",
       "  'antismoking': 1.5980973423117075,\n",
       "  'whateverbr': 1.1926322342035431,\n",
       "  'armin': 0.3941245379857716,\n",
       "  'irredeemably': 2.068100971557443,\n",
       "  'yaint': -0.7044877506823379,\n",
       "  'cãrãmonie': -0.7044877506823379,\n",
       "  'vaginacrazy': -0.7044877506823379,\n",
       "  'interrogatorbr': -0.7044877506823379,\n",
       "  'duckali': -0.7044877506823379,\n",
       "  'remaining': 0.0858231783312552,\n",
       "  'spookybr': -0.7044877506823379,\n",
       "  'communism': -0.1936621269163472,\n",
       "  'suzi': 1.5980973423117075,\n",
       "  'theum': -0.7044877506823379,\n",
       "  'sympathizersbr': -1.1099528587905023,\n",
       "  'rightly': -0.011340570122392868,\n",
       "  'propagating': -1.1099528587905023,\n",
       "  'debased': 0.4994850536435978,\n",
       "  'charitably': 0.6818066104375526,\n",
       "  'entertaining': -0.37248313132084115,\n",
       "  'halfsucceedsbr': 0.6818066104375526,\n",
       "  'mafiosobr': -0.7044877506823379,\n",
       "  'cuteoops': 1.0872717185457168,\n",
       "  'uglified': 0.6818066104375526,\n",
       "  'flightsuited': -0.7044877506823379,\n",
       "  'violate': -0.7044877506823379,\n",
       "  'wear': 0.29766427179820953,\n",
       "  'hollywoodizes': -0.7044877506823379,\n",
       "  'household': -0.7804736576602601,\n",
       "  'worthless': 1.2158890963678106,\n",
       "  'nepotism': 1.374953790997498,\n",
       "  'add': -0.1924507397300504,\n",
       "  'pince': 1.0872717185457168,\n",
       "  'worstand': 1.0872717185457168,\n",
       "  'japp': 0.3941245379857716,\n",
       "  'updike': -0.7044877506823379,\n",
       "  'vd': -0.9276313019965478,\n",
       "  'foggiest': -0.7044877506823379,\n",
       "  'chopped': 0.9500705970322317,\n",
       "  'encapsulating': -1.3976349312422833,\n",
       "  'nashawn': 0.6818066104375526,\n",
       "  'witchwar': 0.6818066104375526,\n",
       "  'ultraconservative': -0.4168056782305571,\n",
       "  'spririt': 0.6818066104375526,\n",
       "  'vieweralmost': -0.7044877506823379,\n",
       "  'sequencesespecially': -0.7044877506823379,\n",
       "  'yugonostalgic': -0.7044877506823379,\n",
       "  'conchita': -0.011340570122392642,\n",
       "  'slapchop': 0.6818066104375526,\n",
       "  'nonadmirer': 0.6818066104375526,\n",
       "  'bettanys': -1.1099528587905023,\n",
       "  'moocow': 1.0872717185457168,\n",
       "  'diniros': -0.7044877506823379,\n",
       "  'pennypinch': -0.7044877506823379,\n",
       "  'ultraliberals': -0.7044877506823379,\n",
       "  'bilancio': 0.6818066104375526,\n",
       "  'forgivenessbut': -0.7044877506823379,\n",
       "  'relish': -1.040959987303551,\n",
       "  'oppress': -0.7044877506823379,\n",
       "  'grittilyrealistic': -0.7044877506823379,\n",
       "  'overlapped': 0.6818066104375526,\n",
       "  'endorsing': -0.7044877506823379,\n",
       "  '73the': -0.7044877506823379,\n",
       "  'koyaanisquatsi': 1.0872717185457168,\n",
       "  'bittime': -0.7044877506823379,\n",
       "  'dimness': -0.7044877506823379,\n",
       "  'âstanislavsky': -0.7044877506823379,\n",
       "  'mastermanbr': -0.7044877506823379,\n",
       "  'lustcontrol': -0.7044877506823379,\n",
       "  'aesir': 1.5980973423117075,\n",
       "  'kubrick': -1.3404765174023348,\n",
       "  'riled': -1.3976349312422833,\n",
       "  'generous': 1.3284337753626052,\n",
       "  'hayward': 0.4994850536435981,\n",
       "  'vixen': -0.5221661938883834,\n",
       "  'striding': -1.3976349312422833,\n",
       "  'croaker': -1.1099528587905023,\n",
       "  'feetthe': -0.7044877506823379,\n",
       "  'clobbering': -0.7044877506823379,\n",
       "  'm1': 1.7804188991056622,\n",
       "  'doberman': -0.011340570122392642,\n",
       "  'stalinist': -1.8031000393504477,\n",
       "  'creasey': 0.6818066104375526,\n",
       "  'crutch': -0.011340570122392868,\n",
       "  'ailmentgod': 1.0872717185457168,\n",
       "  'engagingly': 0.27634150232938826,\n",
       "  'obscurantist': -0.7044877506823379,\n",
       "  'venturebr': 0.6818066104375526,\n",
       "  'raterbr': -0.7044877506823379,\n",
       "  'publicbr': 0.21180298119181692,\n",
       "  'virgin': 0.12479160420218713,\n",
       "  'researcher': -0.6174763736927082,\n",
       "  'jermy': -0.7044877506823379,\n",
       "  'rix': -0.7044877506823379,\n",
       "  'peering': -0.7044877506823379,\n",
       "  'clunky': 1.2016820697234611,\n",
       "  'photoshopped': 0.6818066104375526,\n",
       "  'halfassesd': 0.6818066104375526,\n",
       "  'mainline': 0.6818066104375526,\n",
       "  'exrunaway': 0.6818066104375526,\n",
       "  'viewerscitizens': -0.7044877506823379,\n",
       "  'hillall': -0.7044877506823379,\n",
       "  'noteperfect': -0.7044877506823379,\n",
       "  'sujeong': -0.7044877506823379,\n",
       "  'aryian': -0.7044877506823379,\n",
       "  'compulsion': -0.992169823134119,\n",
       "  'packup': -0.7044877506823379,\n",
       "  'cough': -0.2525026269392808,\n",
       "  'birthmother': -0.7044877506823379,\n",
       "  'endlesslycrying': 1.0872717185457168,\n",
       "  'bizarreness': -0.2990226425741737,\n",
       "  'sheffer': -1.957250719177706,\n",
       "  'unjustifiably': -0.7044877506823379,\n",
       "  'valeries': -1.1099528587905023,\n",
       "  'swipe': -0.011340570122392868,\n",
       "  'runner': -0.6667474226994912,\n",
       "  'creegan': 0.6818066104375526,\n",
       "  'catcus': -0.7044877506823379,\n",
       "  '1942': -0.4466586413802382,\n",
       "  'he': 0.10621887693607751,\n",
       "  'dearestwell': -0.7044877506823379,\n",
       "  'erroll': 0.4994850536435978,\n",
       "  'underacted': -0.7044877506823379,\n",
       "  'rockerbr': -0.7044877506823379,\n",
       "  'elapses': 1.0872717185457168,\n",
       "  'faust': -2.0907821118022287,\n",
       "  'goy': 0.6818066104375526,\n",
       "  'bench': 0.09401994553543364,\n",
       "  'tatu': 2.291244522871653,\n",
       "  'nissan': 1.0872717185457168,\n",
       "  'lint': 0.3941245379857716,\n",
       "  'developmentslines': 0.6818066104375526,\n",
       "  'plateyet': -0.7044877506823379,\n",
       "  'cryâ': -0.7044877506823379,\n",
       "  'timid': -0.5709563580578154,\n",
       "  'knife': 0.37165168213371297,\n",
       "  'hrbr': -0.7044877506823379,\n",
       "  'incorporating': -0.992169823134119,\n",
       "  'limp': 1.1926322342035434,\n",
       "  'imaginable': -0.17385949962016775,\n",
       "  'gaglia': 2.821872773933823,\n",
       "  'gzsz': -1.8031000393504477,\n",
       "  'threestrip': -0.7044877506823379,\n",
       "  'tenbr': -2.0907821118022287,\n",
       "  'measuredbr': -0.7044877506823379,\n",
       "  'crewbr': -0.011340570122392642,\n",
       "  'superdecorative': -0.7044877506823379,\n",
       "  'unites': -0.9276313019965478,\n",
       "  'altho': 0.6818066104375526,\n",
       "  'isntoccurrencesbr': -0.7044877506823379,\n",
       "  'maggiedebbie': -0.7044877506823379,\n",
       "  'overhauled': 1.374953790997498,\n",
       "  'adr': 1.5980973423117075,\n",
       "  'refilming': -0.011340570122392642,\n",
       "  'zephram': -0.7044877506823379,\n",
       "  'appriciate': 0.6818066104375526,\n",
       "  'mooreheads': 0.6818066104375526,\n",
       "  'verhoevens': -0.7845304583558745,\n",
       "  'kyser': 1.5980973423117075,\n",
       "  'grafitti': -1.3976349312422833,\n",
       "  'enhancement': -0.2990226425741737,\n",
       "  'semipsychotic': -0.7044877506823379,\n",
       "  '1hour': 0.6818066104375524,\n",
       "  'showsparticularly': -0.7044877506823379,\n",
       "  'kush': 1.0872717185457168,\n",
       "  'lawbreaking': 0.6818066104375526,\n",
       "  'beute': -0.7044877506823379,\n",
       "  'heand': -0.7044877506823379,\n",
       "  'americashe': 1.0872717185457168,\n",
       "  'bu': 0.27634150232938826,\n",
       "  'requiembr': -0.7044877506823379,\n",
       "  'martyr': 0.14281010970486555,\n",
       "  'bettyyvette': -0.7044877506823379,\n",
       "  'humorist': 0.6818066104375526,\n",
       "  'jamienow': 0.6818066104375526,\n",
       "  'bothhowever': -0.7044877506823379,\n",
       "  'lafanu': -0.7044877506823379,\n",
       "  'stylizes': -0.7044877506823379,\n",
       "  'appreciatesbr': -0.7044877506823379,\n",
       "  'outandback': 1.0872717185457168,\n",
       "  'event': -0.4073837669889382,\n",
       "  'conducting': -0.23448412143660244,\n",
       "  'soba': -0.7044877506823379,\n",
       "  'historyit': 1.0872717185457168,\n",
       "  'timetraveling': 0.3941245379857716,\n",
       "  'dripfeed': -0.7044877506823379,\n",
       "  'deerings': -0.7044877506823379,\n",
       "  'wellyes': -0.7044877506823379,\n",
       "  'directorforhire': -0.7044877506823379,\n",
       "  'massaris': -0.7044877506823379,\n",
       "  'offended': 0.2689613950317656,\n",
       "  'hopedoh': 1.0872717185457168,\n",
       "  'shyama': -0.7044877506823379,\n",
       "  'ghostmovie': -0.7044877506823379,\n",
       "  'stillnovel': 1.374953790997498,\n",
       "  'anticipationand': -0.7044877506823379,\n",
       "  'cohabit': 1.374953790997498,\n",
       "  'proportion': -0.27370483458988387,\n",
       "  'newsreelbr': -0.7044877506823379,\n",
       "  'buttermilk': -0.7044877506823379,\n",
       "  'messanger': -0.7044877506823379,\n",
       "  'dombasle': 1.5980973423117075,\n",
       "  'feelbesides': -0.7044877506823379,\n",
       "  'catchingbut': -0.7044877506823379,\n",
       "  'hobr': -0.011340570122392642,\n",
       "  'lessercelebrated': -0.7044877506823379,\n",
       "  'unfunniest': 1.9345695789329207,\n",
       "  'gob': -0.7044877506823379,\n",
       "  'intervene': 0.27634150232938826,\n",
       "  'comparedcontrasted': 1.0872717185457168,\n",
       "  'propriety': -0.011340570122392868,\n",
       "  'hensonbr': -0.7044877506823379,\n",
       "  'fathersbr': -0.7044877506823379,\n",
       "  'siobhan': -2.0907821118022287,\n",
       "  'wisepaul': -0.7044877506823379,\n",
       "  'clearly': 0.17661480438981797,\n",
       "  'nominal': 0.14281010970486555,\n",
       "  'sodafilled': -0.7044877506823379,\n",
       "  'proficient': -0.4168056782305571,\n",
       "  'reencounters': -0.7044877506823379,\n",
       "  'reheated': 1.0872717185457168,\n",
       "  'watersbr': 1.0872717185457168,\n",
       "  'beersure': 0.6818066104375526,\n",
       "  'radiator': -1.620778482556493,\n",
       "  'fatfree': -0.7044877506823379,\n",
       "  'scathing': -0.16549124994965103,\n",
       "  'repulsively': 0.6818066104375526,\n",
       "  'ladsbr': 1.0872717185457168,\n",
       "  'marth': 1.0872717185457168,\n",
       "  'synder': 1.0872717185457168,\n",
       "  'pre1990s': -0.7044877506823379,\n",
       "  'restricts': -0.4168056782305571,\n",
       "  'processphotography': -0.7044877506823379,\n",
       "  'kusama': -0.011340570122392642,\n",
       "  'uhhh': 0.6818066104375526,\n",
       "  'referred': -0.6303797785286162,\n",
       "  'joanne': -0.3214954984262324,\n",
       "  'recur': -1.3976349312422833,\n",
       "  'streetlampbr': -0.7044877506823379,\n",
       "  'kileybr': -0.7044877506823379,\n",
       "  'comptent': 0.6818066104375526,\n",
       "  'jammin': -0.7044877506823379,\n",
       "  'socializing': -0.4168056782305571,\n",
       "  'traversing': -1.3976349312422833,\n",
       "  'deployed': 0.6818066104375526,\n",
       "  'wilde': -1.1564728744253951,\n",
       "  'arnotts': 0.6818066104375526,\n",
       "  'sirico': -1.620778482556493,\n",
       "  'philanthropic': -0.7044877506823379,\n",
       "  '1996behind': -0.7044877506823379,\n",
       "  'anxiety': -0.5077774564362838,\n",
       "  'raisin': 0.3941245379857716,\n",
       "  'shouldbr': 0.6818066104375526,\n",
       "  'schwarzenneger': -1.1099528587905023,\n",
       "  'gentry': -0.7044877506823379,\n",
       "  'police': -0.17880702592542316,\n",
       "  'unbound': -0.7044877506823379,\n",
       "  'gaybody': 0.6818066104375526,\n",
       "  'shred': 0.7688179874271824,\n",
       "  'bunkum': 1.374953790997498,\n",
       "  'valance': -0.7044877506823379,\n",
       "  'bewitching': -0.7044877506823379,\n",
       "  'airsofts': 0.6818066104375526,\n",
       "  'vignettesbr': 0.27634150232938826,\n",
       "  'anjalis': -1.1099528587905023,\n",
       "  'kahlua': -0.7044877506823379,\n",
       "  'meteor': -0.011340570122392755,\n",
       "  'steven': 0.5160143555948086,\n",
       "  'indicator': 0.6818066104375524,\n",
       "  'whyinsert': -0.7044877506823379,\n",
       "  'kapadia': -1.1099528587905023,\n",
       "  'onpoint': -0.7044877506823379,\n",
       "  'balduin': -2.0907821118022287,\n",
       "  'commodified': -0.7044877506823379,\n",
       "  'zinfandel': -0.7044877506823379,\n",
       "  'flange': 2.1858840072138266,\n",
       "  'witnessedand': 0.6818066104375526,\n",
       "  'partysdp': 0.6818066104375526,\n",
       "  'gary': -0.3073214453888688,\n",
       "  'sameplot': 0.6818066104375526,\n",
       "  'loverâ': -1.1099528587905023,\n",
       "  'mackaill': -0.7044877506823379,\n",
       "  'nobr': 0.6818066104375526,\n",
       "  'zangief': 1.374953790997498,\n",
       "  'crappily': 0.3941245379857716,\n",
       "  'andalucia': -0.7044877506823379,\n",
       "  'valentinecertainly': 0.6818066104375526,\n",
       "  'nowsingle': -0.7044877506823379,\n",
       "  'gough': -1.3106235542526534,\n",
       "  'swim': -0.7318867248704526,\n",
       "  'movieexperiments': -0.7044877506823379,\n",
       "  'outruns': -0.7044877506823379,\n",
       "  'meanmaybe': 1.0872717185457168,\n",
       "  'nroll': -1.1099528587905023,\n",
       "  'appealingbr': 0.6818066104375526,\n",
       "  'rcci': -0.7044877506823379,\n",
       "  'fatbr': 1.0872717185457168,\n",
       "  'duetit': -0.7044877506823379,\n",
       "  'moviemakingbr': -0.7044877506823379,\n",
       "  'forysthe': -0.7044877506823379,\n",
       "  'ploteverybody': -0.7044877506823379,\n",
       "  'wine': 0.23712078917610682,\n",
       "  'zu': -0.8586384305095963,\n",
       "  'andwell': -0.011340570122392868,\n",
       "  'deific': -0.7044877506823379,\n",
       "  'impliesbr': -0.011340570122392642,\n",
       "  'hitchhikerno': 0.6818066104375526,\n",
       "  'doesi': -0.7044877506823379,\n",
       "  'milliardo': -0.7044877506823379,\n",
       "  'tengo': -0.7044877506823379,\n",
       "  'sri': -0.8868093074762928,\n",
       "  'clippie': 0.6818066104375526,\n",
       "  'openheart': 0.6818066104375526,\n",
       "  'marat': 1.0872717185457168,\n",
       "  'hoarding': 0.27634150232938826,\n",
       "  'pegasus': -1.3976349312422833,\n",
       "  'phar': -0.7044877506823379,\n",
       "  'whilebr': -1.292274415584457,\n",
       "  'tearsbr': -1.1099528587905023,\n",
       "  'routing': 0.27634150232938826,\n",
       "  'aftereffectsbr': -0.7044877506823379,\n",
       "  'wander': 1.0872717185457168,\n",
       "  'doomladen': -0.011340570122392642,\n",
       "  'leelee': -0.011340570122392868,\n",
       "  'digitallyrestored': 1.374953790997498,\n",
       "  'departmentsdavid': -0.7044877506823379,\n",
       "  'disbeliefbr': 0.6818066104375526,\n",
       "  'graverobbing': -1.1099528587905023,\n",
       "  'discovered': -0.36571401707284606,\n",
       "  'jimbr': -0.7044877506823379,\n",
       "  'fella': -0.37906535024771026,\n",
       "  'shecky': 1.374953790997498,\n",
       "  'woolcott': -1.3976349312422833,\n",
       "  'aggressionbr': 1.0872717185457168,\n",
       "  'threenine': -0.7044877506823379,\n",
       "  'calculus': 0.3941245379857716,\n",
       "  'llama': 0.3941245379857716,\n",
       "  'starhe': -0.7044877506823379,\n",
       "  'websiteimdb': -0.7044877506823379,\n",
       "  'wrongi': -1.1099528587905023,\n",
       "  'gruffudd': -1.1099528587905023,\n",
       "  'inclined': -0.39433282237849837,\n",
       "  'paramilitarylike': 0.6818066104375526,\n",
       "  'byers': 1.0872717185457168,\n",
       "  'annibal': -0.7044877506823379,\n",
       "  'macallums': 1.0872717185457168,\n",
       "  'paytv': -1.1099528587905023,\n",
       "  'waken': -0.7044877506823379,\n",
       "  'namak': -1.1099528587905023,\n",
       "  'aamir': -1.5154179668986667,\n",
       "  'nutof': 0.6818066104375526,\n",
       "  'scrumptious': 0.6818066104375526,\n",
       "  'germanyreally': 0.6818066104375526,\n",
       "  'mumbojumbobr': -0.7044877506823379,\n",
       "  'againhoping': -0.7044877506823379,\n",
       "  '2505': -1.1099528587905023,\n",
       "  'foulness': -0.7044877506823379,\n",
       "  'colorful': -0.7190865501034909,\n",
       "  'munnerala': 1.0872717185457168,\n",
       "  'protagonistmailman': 1.374953790997498,\n",
       "  'preplastic': -0.7044877506823379,\n",
       "  'wellspent': -1.1099528587905023,\n",
       "  'rehashing': 1.0182788470587654,\n",
       "  'strategicallyplaced': 0.6818066104375526,\n",
       "  'isill': 0.6818066104375526,\n",
       "  'favoursbr': 0.6818066104375526,\n",
       "  'suitplayed': 1.5980973423117075,\n",
       "  'uncontested': 0.6818066104375526,\n",
       "  'draftee': 1.0872717185457168,\n",
       "  'thistrash': 0.6818066104375526,\n",
       "  'fued': -0.7044877506823379,\n",
       "  'aldrin': 1.9345695789329207,\n",
       "  'itya': 1.374953790997498,\n",
       "  'beaner': 1.0872717185457168,\n",
       "  'ryoko': 1.0872717185457168,\n",
       "  'madefor': 1.0872717185457168,\n",
       "  'settons': -0.7044877506823379,\n",
       "  'borough': -0.5991272350245117,\n",
       "  'snaky': -0.7044877506823379,\n",
       "  'contestantoscar': 0.6818066104375526,\n",
       "  'hollywoodizing': 0.6818066104375526,\n",
       "  'edwardian': -0.8222707863387214,\n",
       "  'wladyslaw': -1.3976349312422833,\n",
       "  'oja': 0.6818066104375526,\n",
       "  'prosperos': -0.011340570122392642,\n",
       "  'limelight': -0.14487196274691527,\n",
       "  'suicidebr': 0.6818066104375526,\n",
       "  'terrorized': 0.39412453798577146,\n",
       "  'unremarkableness': -0.7044877506823379,\n",
       "  'brommel': -1.1099528587905023,\n",
       "  'beforebr': 0.39412453798577174,\n",
       "  'worksas': 0.6818066104375526,\n",
       "  'foxxbr': -0.7044877506823379,\n",
       "  'reset': 0.6818066104375526,\n",
       "  'imdfb': 0.6818066104375526,\n",
       "  'rennes': 1.5980973423117075,\n",
       "  'manifestbr': -0.7044877506823379,\n",
       "  'rightshe': -0.7044877506823379,\n",
       "  'clarity': 0.045817843717555755,\n",
       "  'algeria': -0.7044877506823379,\n",
       "  'lisabr': 1.0872717185457168,\n",
       "  'incomparably': -0.7044877506823379,\n",
       "  'mussed': -0.7044877506823379,\n",
       "  'inspiredthe': -0.7044877506823379,\n",
       "  '82199': 1.0872717185457168,\n",
       "  'meltingpot': 1.374953790997498,\n",
       "  'vitae': 0.6818066104375526,\n",
       "  'dobr': 0.11002028688187449,\n",
       "  'arbor': 1.0872717185457168,\n",
       "  'lessersitcom': 0.6818066104375526,\n",
       "  'vento': -0.7044877506823379,\n",
       "  'adventureits': -0.7044877506823379,\n",
       "  'dbr': 0.54827521781303,\n",
       "  'sticker': 1.2414223983729753,\n",
       "  'dalmation': 0.6818066104375526,\n",
       "  'sayer': -0.7044877506823379,\n",
       "  'ryokobr': 0.6818066104375526,\n",
       "  'manhating': 0.6818066104375526,\n",
       "  'jaggerbr': -0.7044877506823379,\n",
       "  'sweating': -0.4168056782305571,\n",
       "  'flockofducks': 0.6818066104375526,\n",
       "  '1931featured': -0.7044877506823379,\n",
       "  'lostintranslation': 1.374953790997498,\n",
       "  'blackbird': 0.3941245379857716,\n",
       "  'drowns': 0.2399738581585132,\n",
       "  'indeedbr': 0.6818066104375524,\n",
       "  'jacking': 0.9049501617517622,\n",
       "  'greave': -2.3139256631164384,\n",
       "  'creatureslets': 0.6818066104375526,\n",
       "  'bagdad': -2.7839292923621737,\n",
       "  'columnistsbr': -0.7044877506823379,\n",
       "  'whateverthe': 0.3941245379857716,\n",
       "  'smilodons': 0.6818066104375526,\n",
       "  'praising': 0.4586630591233429,\n",
       "  'gypo': -3.412537951784548,\n",
       "  'keisha': -0.7044877506823379,\n",
       "  'marla': -0.2990226425741737,\n",
       "  'contributionbr': -1.1099528587905023,\n",
       "  'longuers': 1.374953790997498,\n",
       "  'lost': 0.06460058311299018,\n",
       "  'ambitiousness': 0.3941245379857716,\n",
       "  'beforebut': -1.1099528587905023,\n",
       "  'bflick': -0.011340570122392868,\n",
       "  'cline': 0.27634150232938826,\n",
       "  'anderslittle': 1.0872717185457168,\n",
       "  'fannie': 0.6818066104375526,\n",
       "  'musicyikes': 0.6818066104375526,\n",
       "  'commended': 0.10644246553399071,\n",
       "  'muldrun': -0.7044877506823379,\n",
       "  'stairway': -1.908460555008274,\n",
       "  'perfectlybr': -0.4168056782305571,\n",
       "  'pinching': -0.7044877506823379,\n",
       "  'tongueincheek': 0.04928405169404204,\n",
       "  'pathbr': -0.2990226425741737,\n",
       "  'luchino': -2.208565147458612,\n",
       "  'ralph': -0.5932621155721137,\n",
       "  'everythingwhen': 0.6818066104375526,\n",
       "  'roeves': 1.8604616067791988,\n",
       "  'extramarital': -1.1099528587905023,\n",
       "  'parolebr': -0.7044877506823379,\n",
       "  'drame': -0.7044877506823379,\n",
       "  'monde': 1.0872717185457168,\n",
       "  'amicus': -1.3976349312422833,\n",
       "  'godfreys': -0.7044877506823379,\n",
       "  'plotlessalthough': -0.7044877506823379,\n",
       "  'wegier': -0.7044877506823379,\n",
       "  'yourselfbr': -1.3976349312422833,\n",
       "  'wobbly': 0.4586630591233429,\n",
       "  'bacalls': -1.1099528587905023,\n",
       "  'freaked': -0.17839465478555902,\n",
       "  'mcdonnells': -0.7044877506823379,\n",
       "  'disproved': 1.0872717185457168,\n",
       "  'amends': -0.1936621269163475,\n",
       "  'wood': 0.491498702010948,\n",
       "  'nakadeibr': -0.7044877506823379,\n",
       "  'outward': -0.2990226425741737,\n",
       "  'poor': 1.3348146234071534,\n",
       "  'tourguide': -0.7044877506823379,\n",
       "  'sickeningâ': 1.0872717185457168,\n",
       "  'genghis': -1.1099528587905023,\n",
       "  'appraisal': -0.7044877506823379,\n",
       "  'crowdpleaser': -0.011340570122392642,\n",
       "  'inflates': -0.7044877506823379,\n",
       "  'manycolored': -0.7044877506823379,\n",
       "  'babysat': -0.7044877506823379,\n",
       "  'salina': -1.1099528587905023,\n",
       "  'prepareit': 0.6818066104375526,\n",
       "  '2furious': -0.7044877506823379,\n",
       "  'camerawork': 0.5659747949124307,\n",
       "  'doorsbr': -0.7044877506823379,\n",
       "  'col': -1.620778482556493,\n",
       "  'caitlin': -0.4168056782305571,\n",
       "  'potency': -0.7044877506823379,\n",
       "  'stiffand': 0.6818066104375526,\n",
       "  'preferred': -0.6303797785286162,\n",
       "  'outlawsbr': -1.1099528587905023,\n",
       "  'yetgive': -0.7044877506823379,\n",
       "  'bitching': 0.4994850536435978,\n",
       "  'humanization': 0.6818066104375526,\n",
       "  'oo': 0.6818066104375526,\n",
       "  'blaming': 0.8641281672315072,\n",
       "  'pegged': 0.27634150232938826,\n",
       "  'hawksian': -0.7044877506823379,\n",
       "  'teek': -0.7044877506823379,\n",
       "  'getokso': 0.6818066104375526,\n",
       "  'horrorthriller': 0.35638421000292464,\n",
       "  'dialogdriven': 0.6818066104375526,\n",
       "  'formalism': -1.3976349312422833,\n",
       "  'shinto': -0.7044877506823379,\n",
       "  'mecanic': -0.7044877506823379,\n",
       "  'cupidon': -1.1099528587905023,\n",
       "  'wimmen': 1.0872717185457168,\n",
       "  'madeperiodbr': -0.7044877506823379,\n",
       "  'rasuadli': -1.1099528587905023,\n",
       "  'putall': -0.7044877506823379,\n",
       "  'nobleman': -0.23448412143660244,\n",
       "  'horehound': -0.7044877506823379,\n",
       "  'sequencefollowed': -0.7044877506823379,\n",
       "  '30lbs': -0.7044877506823379,\n",
       "  'priggish': -0.4168056782305571,\n",
       "  'existedbr': -0.011340570122392868,\n",
       "  'understating': -1.1099528587905023,\n",
       "  'deusexmachina': 0.6818066104375526,\n",
       "  'heffner': -0.7044877506823379,\n",
       "  'ubernew': 0.6818066104375526,\n",
       "  'touchyfeely': 0.9049501617517622,\n",
       "  'ladont': -0.7044877506823379,\n",
       "  'masterpiecethat': -0.7044877506823379,\n",
       "  'balabanov': 1.374953790997498,\n",
       "  'fabric': -0.23448412143660244,\n",
       "  'fortuitously': 0.6818066104375526,\n",
       "  'dragonbr': -0.7044877506823379,\n",
       "  'affectationsbr': 1.0872717185457168,\n",
       "  'badassdom': 1.374953790997498,\n",
       "  'anywaybut': -0.7044877506823379,\n",
       "  'knockdown': 1.5980973423117075,\n",
       "  'selick': -1.3976349312422833,\n",
       "  'hoeys': -1.1099528587905023,\n",
       "  'cleaned': -0.4168056782305571,\n",
       "  'downloading': 0.17098098667156192,\n",
       "  'nondirection': 0.6818066104375526,\n",
       "  'uncamply': -0.7044877506823379,\n",
       "  'seascape': -0.7044877506823379,\n",
       "  'happpy': -0.7044877506823379,\n",
       "  'vercors': 1.0872717185457168,\n",
       "  'allnaked': -0.7044877506823379,\n",
       "  'badtaste': 0.6818066104375526,\n",
       "  'yun': -1.3976349312422833,\n",
       "  'bethany': -0.7044877506823382,\n",
       "  'teardripping': -0.7044877506823379,\n",
       "  'nathans': -1.620778482556493,\n",
       "  'decentmaking': -0.7044877506823379,\n",
       "  'franky': 2.068100971557443,\n",
       "  'keener': -0.23448412143660244,\n",
       "  'predictible': 1.0872717185457168,\n",
       "  'wasthe': -1.3976349312422833,\n",
       "  'findesiecle': -0.7044877506823379,\n",
       "  'comedicromantic': -0.7044877506823379,\n",
       "  'faggedout': 1.0872717185457168,\n",
       "  'colemans': -1.1099528587905023,\n",
       "  'idis': 1.0872717185457168,\n",
       "  'asbestos': 0.4994850536435978,\n",
       "  'needle': 0.19922419898495694,\n",
       "  'juon': 0.9331210387184585,\n",
       "  'indiscreet': -0.7044877506823379,\n",
       "  'tutankhamen': -0.7044877506823379,\n",
       "  'owns': -0.10978064293564525,\n",
       "  'growingupâ': -0.7044877506823379,\n",
       "  'occultâ': 1.0872717185457168,\n",
       "  'newell': -0.7044877506823379,\n",
       "  'daydreamer': -0.7044877506823379,\n",
       "  'duncan': 0.1999685235448141,\n",
       "  'acquiescing': -0.7044877506823379,\n",
       "  'firstis': -0.7044877506823379,\n",
       "  'instigate': 0.3941245379857716,\n",
       "  'curb': -0.09835194711202257,\n",
       "  'janmicheal': -0.7044877506823379,\n",
       "  'laterlike': -0.7044877506823379,\n",
       "  'revisiting': -0.5709563580578154,\n",
       "  'monthsthe': 0.6818066104375526,\n",
       "  'xmasbr': 1.0872717185457168,\n",
       "  'lackthereofbr': 0.6818066104375526,\n",
       "  'silicone': 0.4994850536435978,\n",
       "  'world': -0.6381029940210055,\n",
       "  'miserly': 0.6818066104375526,\n",
       "  'gurda': -0.7044877506823379,\n",
       "  'substory': -0.011340570122392642,\n",
       "  'kidsits': -0.7044877506823379,\n",
       "  'kumars': 0.3941245379857716,\n",
       "  'cactus': -1.957250719177706,\n",
       "  'footage': 0.4036939890019222,\n",
       "  'zlevel': 1.0872717185457168,\n",
       "  'skoda': 1.0872717185457168,\n",
       "  'fatigue': 0.32513166649882014,\n",
       "  'footnote': 0.2399738581585132,\n",
       "  'whereaboutsto': -0.7044877506823379,\n",
       "  'chapeau': -0.7044877506823379,\n",
       "  'hatefully': -0.7044877506823379,\n",
       "  'cmndt': -0.7044877506823379,\n",
       "  'jus': -0.7044877506823379,\n",
       "  'televise': -0.7044877506823379,\n",
       "  'poseur': -0.011340570122392642,\n",
       "  'hennessy': -2.0907821118022287,\n",
       "  'againmaybe': -0.7044877506823379,\n",
       "  'lamico': -0.7044877506823379,\n",
       "  'wifebehind': -0.7044877506823379,\n",
       "  'steam': 0.4586630591233429,\n",
       "  'haara': 0.6818066104375526,\n",
       "  'aclu': 0.6818066104375526,\n",
       "  'amores': -0.7044877506823379,\n",
       "  'centralized': -0.7044877506823379,\n",
       "  'casimir': -0.011340570122392642,\n",
       "  'pantheist': -0.7044877506823379,\n",
       "  'simpletoo': 0.6818066104375526,\n",
       "  'lindley': 0.6818066104375526,\n",
       "  'girlhood': -0.7044877506823379,\n",
       "  'indicated': 0.3941245379857716,\n",
       "  'indeliberately': 0.6818066104375526,\n",
       "  'debbuzi': -0.7044877506823379,\n",
       "  'finest': -1.8207996164498488,\n",
       "  'delve': -0.057860585757285476,\n",
       "  'castthats': 0.6818066104375526,\n",
       "  'klause': 0.3941245379857716,\n",
       "  'deathshortly': -0.7044877506823379,\n",
       "  'disassociate': -0.7044877506823379,\n",
       "  'seminary': -0.011340570122392642,\n",
       "  'suberb': -0.7044877506823379,\n",
       "  'nearbye': -0.7044877506823379,\n",
       "  'daysbr': -0.3596472643906084,\n",
       "  'thornes': 1.0872717185457168,\n",
       "  'thurston': -0.7044877506823379,\n",
       "  'sheerly': 1.0872717185457168,\n",
       "  'lender': -0.7044877506823379,\n",
       "  'machts': 1.0872717185457168,\n",
       "  'transpired': 0.6818066104375524,\n",
       "  'mehboobababban': 1.0872717185457168,\n",
       "  'terrorismbr': -0.011340570122392642,\n",
       "  'economic': -0.5374336660191719,\n",
       "  'compensating': -0.2990226425741737,\n",
       "  'snart': -1.1099528587905023,\n",
       "  'soundgarden': 1.0872717185457168,\n",
       "  'deputize': -0.7044877506823379,\n",
       "  'wakefields': -0.7044877506823379,\n",
       "  'vredens': -0.7044877506823379,\n",
       "  'teahow': -0.7044877506823379,\n",
       "  'fictionthe': 1.374953790997498,\n",
       "  'oneshouldered': -0.7044877506823379,\n",
       "  'indecisiveness': -0.011340570122392642,\n",
       "  'golgotha': -0.7044877506823379,\n",
       "  'silliness': 0.08103275000862221,\n",
       "  'decadesbr': -0.7044877506823379,\n",
       "  'incurable': -0.9276313019965478,\n",
       "  'nextrobert': 0.6818066104375526,\n",
       "  'teenagegirls': -0.7044877506823379,\n",
       "  'harhar': 1.5980973423117075,\n",
       "  'talkie': -1.0817819818238061,\n",
       "  'dax': 0.9049501617517622,\n",
       "  'kuzco': 2.2573429711959716,\n",
       "  'intervention': -0.32979430124092723,\n",
       "  'tieney': -0.7044877506823379,\n",
       "  'craigbr': -0.7044877506823379,\n",
       "  'surely': 0.06416698238575237,\n",
       "  'postintolerance': -0.7044877506823379,\n",
       "  'glisten': -0.011340570122392642,\n",
       "  'belongmonstervision': -0.7044877506823379,\n",
       "  'indiansam': -0.7044877506823379,\n",
       "  'bubba': 0.27634150232938826,\n",
       "  'wikpedia': -0.7044877506823379,\n",
       "  'watchingwaitingfor': 0.6818066104375526,\n",
       "  'usbased': -0.7044877506823379,\n",
       "  'twotime': -0.4168056782305571,\n",
       "  'houghton': 0.3941245379857716,\n",
       "  'hector': -0.2990226425741739,\n",
       "  'fosse': -0.011340570122392642,\n",
       "  'overdid': 0.6818066104375526,\n",
       "  'haiduk': 0.6818066104375526,\n",
       "  'sadoul': -1.1099528587905023,\n",
       "  'tarr': -0.4168056782305571,\n",
       "  'wrecking': -1.3976349312422833,\n",
       "  'regulated': -0.7044877506823379,\n",
       "  'lengle': 0.6818066104375526,\n",
       "  'nightbeast': 2.627716759492866,\n",
       "  'forsyth': -1.620778482556493,\n",
       "  'ferdinamyhave': -0.7044877506823379,\n",
       "  '25': 0.030623628976639387,\n",
       "  'animated': -0.7002050888903373,\n",
       "  'disregardedbr': 0.6818066104375526,\n",
       "  'absolve': -0.7044877506823379,\n",
       "  'neatly': -1.0017392741502698,\n",
       "  'sydrome': -0.7044877506823379,\n",
       "  'spiritualbr': -0.7044877506823379,\n",
       "  'mcintire': -1.189995566464039,\n",
       "  'preferable': -0.011340570122392755,\n",
       "  'sixguns': 0.6818066104375526,\n",
       "  'meringue': -0.7044877506823379,\n",
       "  'cramp': 1.0872717185457168,\n",
       "  'diabolically': 2.1858840072138266,\n",
       "  'hourbut': 1.374953790997498,\n",
       "  'killshots': 1.0872717185457168,\n",
       "  'rapidshare': 0.6818066104375526,\n",
       "  'thornesmith': 1.374953790997498,\n",
       "  'emulating': 0.6818066104375526,\n",
       "  'thinly': 0.39412453798577146,\n",
       "  'abdulrahman': 1.0872717185457168,\n",
       "  'distributedbr': 0.6818066104375526,\n",
       "  'miraculously': 1.780418899105662,\n",
       "  'unkiddy': 1.0872717185457168,\n",
       "  'mizoguchis': -1.3976349312422833,\n",
       "  'descending': -0.8222707863387214,\n",
       "  'jalal': 0.8359572902648108,\n",
       "  'thingsi': 0.6818066104375526,\n",
       "  'whiny': 1.0182788470587654,\n",
       "  'sandlot': 1.0872717185457168,\n",
       "  'itsã': -0.7044877506823379,\n",
       "  'pseudovictorian': 0.6818066104375526,\n",
       "  'portays': -0.7044877506823379,\n",
       "  'greystoke': -0.7044877506823382,\n",
       "  'fluctuates': 0.6818066104375526,\n",
       "  'underdelivered': 0.6818066104375526,\n",
       "  'noncopout': -0.7044877506823379,\n",
       "  'specializes': -1.620778482556493,\n",
       "  'yolande': -1.1099528587905023,\n",
       "  'sundayafternoon': 1.0872717185457168,\n",
       "  ...})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading model parameters from local file \n",
    "with open('NB.pickle', 'rb') as f:\n",
    "     data = pickle.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703014d7",
   "metadata": {},
   "source": [
    "#### 7.3) Print confusion matrix for training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60b8644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predictions \n",
    "y_hat = []\n",
    "for i in X_train:\n",
    "    y_hat.append(naive_bayes_predict(i,NB[0],NB[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e7eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9417,  583],\n",
       "       [ 529, 9471]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for traning set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_train, y_hat)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9c8317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set accuracy \n",
    "test_naive_bayes(X_train, y_train, NB[0], NB[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "889f0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_t = []\n",
    "for i in X_test:\n",
    "    y_hat_t.append(naive_bayes_predict(i,NB[0],NB[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1d201b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2216,  258],\n",
       "       [ 307, 2167]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for test set\n",
    "cnf_matrix = confusion_matrix(y_test, y_hat_t)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1625fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858124494745352"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set accuracy \n",
    "test_naive_bayes(X_test, y_test, NB[0], NB[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526532de",
   "metadata": {},
   "source": [
    "#### 7.4) Examine False Positive and False Negative cases and provide reasoning why they get misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9685d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame()\n",
    "dfs['test'] = X_test\n",
    "dfs = dfs.reset_index()\n",
    "y_t = y_test.reset_index()\n",
    "dfs['y_test'] = y_t['sentiment']\n",
    "dfs['y_predict'] = y_hat_t\n",
    "dfs.to_csv('analyzes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec9b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13512</td>\n",
       "      <td>Well, EYEboy, I must say that it pleases me to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17245</td>\n",
       "      <td>A potentially good idea gets completely let do...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24069</td>\n",
       "      <td>While most of Wayne's B efforts are entertaini...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22347</td>\n",
       "      <td>I thought maybe a film which boasted a cast in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>916</td>\n",
       "      <td>Mickey Rourke hunts Diane Lane in Elmore Leona...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>17134</td>\n",
       "      <td>I tuned in to this movie because there was not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>18977</td>\n",
       "      <td>\"The Case of the Scorpion's Tail\" has all the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>4824</td>\n",
       "      <td>This film is not really a remake of the 1949 O...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>6631</td>\n",
       "      <td>I bought this movie a few days ago, and though...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>19155</td>\n",
       "      <td>This movie changed it all for me...I heard of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4948 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               test  y_test  \\\n",
       "0     13512  Well, EYEboy, I must say that it pleases me to...       1   \n",
       "1     17245  A potentially good idea gets completely let do...       1   \n",
       "2     24069  While most of Wayne's B efforts are entertaini...       1   \n",
       "3     22347  I thought maybe a film which boasted a cast in...       1   \n",
       "4       916  Mickey Rourke hunts Diane Lane in Elmore Leona...       1   \n",
       "...     ...                                                ...     ...   \n",
       "4943  17134  I tuned in to this movie because there was not...       0   \n",
       "4944  18977  \"The Case of the Scorpion's Tail\" has all the ...       0   \n",
       "4945   4824  This film is not really a remake of the 1949 O...       0   \n",
       "4946   6631  I bought this movie a few days ago, and though...       0   \n",
       "4947  19155  This movie changed it all for me...I heard of ...       0   \n",
       "\n",
       "      y_predict  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "4943          1  \n",
       "4944          0  \n",
       "4945          1  \n",
       "4946          0  \n",
       "4947          0  \n",
       "\n",
       "[4948 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92711a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review = 'While Im normally a big fan of John Turturros work as an actor and director, ILLUMINATA is a great disappointment. Although the film has some charming moments, overall it falls flat. Worst of all, the film is confusing. Where is the movie set? Italy or an Italian troupe in New York? Why bother making a historical film if it fails to convey a setting? If you want to see a well-made, inspiring historical film also about theater, go see Tim Robbins THE CRADLE WILL ROCK. This movie has many pluses, including a fine performance by John Turturro.'\n",
    "naive_bayes_predict(my_review, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a88a5",
   "metadata": {},
   "source": [
    "The review above is an example of a false positive; it is clear from the review that it was misclassified due to multipolarity because the word \"huge fan\" likely caused the predictor to classify the review as positive even though it was unable to comprehend its context. Later in the review, it is noted as a \"huge disappointment,\" which the classifier missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "038bb0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review = 'It isnt the worst film ever made, the actors arent apalling and the script and director are not completely inept. <br /><br />It isnt the best film ever made, the actors arent excellent and the script and director are not completely brilliant.<br /><br />It falls somewhere in the middle. A fun somewhere. An enjoyable, well constructed somewhere.<br /><br />No need to say \"dont take it seriously\" or \"so bad its good\" or \"it wasnt scary\". None of these comments are relevant. <br /><br />Cut has atmosphere. Its that atmosphere which is actually very unique, and the one really original aspect of the movie, which personally is what makes the film, for me.'\n",
    "naive_bayes_predict(my_review, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601e505",
   "metadata": {},
   "source": [
    "Because of the sarcasm employed in this review, the one above is an example of a fake negative. A different explanation might include poor negation detection. The emotion classifier was baffled by the claim that this isn't the best movie ever made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b033f18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_review= 'This is a typical Sandra Bullock movie in which she plays a mousy (but profane) woman who is in trouble but finds a way to survive and be the hero. Sound familiar? <br /><br />There are plenty of holes in this story. Things just dont add up and some of the suspense is a little corny. But - that suspense is very good. There is a lot of tension in this story which has strong paranoia running through it. The story starts off slow but kicks in pretty soon and stays that way, making it an involving movie for the viewer. That is why I give it a pretty good rating - the movie gets you involved in it. Bullock is more cute than annoying, which she normally is to me, so this is my highest-rated movie with her in it.'\n",
    "naive_bayes_predict(my_review, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84a6c",
   "metadata": {},
   "source": [
    "This review is an illustration of a false negative. This review is quite ambiguous because it initially criticizes the film before giving it a high rating. Another illustration of word ambiguity is this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39d082",
   "metadata": {},
   "source": [
    "### After analyzing many false negatives and false positives , I found the following 4 main reasons for false negatives and false positives \n",
    "\n",
    "#### 1. One reason for False positive could be use of sarcasm. \n",
    "\n",
    "People use sarcastic writing to express their negative emotions in a positive way. As a result, sarcasm can easily trick sentiment analysis systems unless they are specifically designed to take it into account.\n",
    "\n",
    "#### 2. Faulty Negation Detection could be reason for False negative.\n",
    "A method for flipping the polarity of words, phrases, and even whole sentences is negation. Many linguistic criteria are used by researchers to determine whether negation is occurring, but it's also crucial to identify the words that are impacted by negation terms. The scope of the sentence \"The show was not interesting,\" for instance, is limited to the word that comes after the negation word. The effect of the negation word \"not,\" however, lasts just until the end of sentences like \"I do not call this movie a comedy movie.\" Positive or negative terms that are included in the negation shift from their original meaning and take on the opposite polarity.\n",
    "\n",
    "#### 3. Word Ambiguity is another reason for FP and FN \n",
    "It is challenging to develop a universal opinion lexicon containing polarities for all words because word polarity varies by domain. For instance:\n",
    "\n",
    "“The story is unpredictable.”\n",
    "“The steering wheel is unpredictable.”\n",
    "These two instances demonstrate how context impacts the emotion of opinion words. The word polarity \"unpredictable\" is anticipated to be positive in the first scenario. The identical term has a negative polarity in the second.\n",
    "\n",
    "#### 4. Multipolarity - reason for FP and FN \n",
    "\n",
    "Let's look at an illustration with multiple polarities: \"My new laptop's audio quality is amazing, but the colors on the screens aren't that great.\"\n",
    "Some sentiment analysis models will give this sentence a neutral or negative valence.\n",
    "\n",
    "https://www.toptal.com/deep-learning/4-sentiment-analysis-accuracy-traps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XbzttYVnBo7W",
   "metadata": {
    "id": "XbzttYVnBo7W"
   },
   "source": [
    "# Q8. Modularize your calssifier (10 points)\n",
    "1. Convert your code into a python module text_classifier.py\n",
    "\n",
    "2. The user should be able to launch the application on command prompt using python test_classifier.py command. The module will automatically load the model paramters from a local file of your choice and be ready to take the input from user on command prompt. The program will preprocess user input, tokenize and predict the class.\n",
    "\n",
    "3. Your module will take the input from user and output sentiment class in an indefinite loop. The output should printout the probabilities for each input token along with the final classification decision. Program will quit if user enters X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d954b",
   "metadata": {
    "id": "lKAQrnnbBnKe"
   },
   "source": [
    "**Attached the files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6e4d1",
   "metadata": {
    "id": "82e6e4d1"
   },
   "source": [
    "# Q9. Theory Questions: (10 points)\n",
    "\n",
    "1. Why is Laplace Smoothing or Additive Smoothing required while executing Naive Bayes operations, especially for text classification? Show how not having additive smoothing leads to bad outcomes by using an example of training and the test set. (10 points)\n",
    "\n",
    "\n",
    "2. Why are logarithmic values computed instead of only probability values in the Naive Bayes algorithm? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aff585",
   "metadata": {},
   "source": [
    "#### Q9.1) Why is Laplace Smoothing or Additive Smoothing required while executing Naive Bayes operations, especially for text classification?\n",
    "\n",
    "When implementing naive bayes, laplace smoothing is necessary since some words in the input text might not be in the training set, making it impossible to assess their likelihood, let alone disregard it or treat it as zero. Both will produce false results.\n",
    "\n",
    "Ignoring the term means we are assigning it probability of 1 -> Not correct\n",
    "\n",
    "If likelihood is considered 0 means, the probability of entire text becomes 0 -> Not correct\n",
    "\n",
    "This problem is solved by laplace smoothing. It is a a method of smoothing that addresses Naive Bayes' issue with zero probability. It does this by increasing the zero probability values to a small positive number and decreasing other values in proportion, keeping the sum at 1.\n",
    "\n",
    "Since not all words may be present in the training set for text categorization, laplace smoothing is particularly crucial. Suppose we had to categorize email as spam or ham, for instance. Without utilizing laplace smoothing, we won't be able to accurately identify the text if the input email contains a word that isn't in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2b4fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Without Laplace smoothing traning function\n",
    "\n",
    "def train_naive_bayes_ls(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of reviews\n",
    "        train_y: a list of labels correponding to the reviews (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set(list(zip(*freqs))[0])\n",
    "    V = len(vocab)\n",
    "\n",
    "\n",
    "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
    "    num_pos = num_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "             num_pos = num_pos + freqs[pair]\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "                # increment the number of negative words by the count for this (word,label) pair\n",
    "            num_neg = num_neg + freqs[pair] \n",
    "\n",
    "    # Calculate num_doc, the number of documents\n",
    "    num_doc = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents \n",
    "    pos_num_docs = train_y.value_counts()[0]\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    neg_num_docs = train_y.value_counts()[1]\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(neg_num_docs/pos_num_docs)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = find_occurrence(freqs,word,0)\n",
    "        freq_neg = find_occurrence(freqs,word,1)\n",
    "\n",
    "        # without laplace smoothing\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos) / (num_pos) \n",
    "        p_w_neg = (freq_neg) / (num_neg)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_neg/p_w_pos)\n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e254f158",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m logprior, loglikelihood \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_naive_bayes_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(logprior)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loglikelihood))\n",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36mtrain_naive_bayes_ls\u001b[1;34m(freqs, train_x, train_y)\u001b[0m\n\u001b[0;32m     59\u001b[0m     p_w_neg \u001b[38;5;241m=\u001b[39m (freq_neg) \u001b[38;5;241m/\u001b[39m (num_neg)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# calculate the log likelihood of the word\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     loglikelihood[word] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mp_w_neg\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mp_w_pos\u001b[49m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logprior, loglikelihood\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
    "logprior, loglikelihood = train_naive_bayes_ls(freqs, X_train, y_train)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e753d",
   "metadata": {},
   "source": [
    "Because some of the words never appear in the train or test set and have 0 probability, the model will throw an error if it is trained without employing laplace smoothing, as was seen above. Because we cannot divide by zero any number, the code raises an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d5fca3",
   "metadata": {},
   "source": [
    "#### Q9.2) Why are logarithmic values computed instead of only probability values in the Naive Bayes algorithm? \n",
    "\n",
    "Probabilities can have values ranging from 0 to 1. When we add many of these probabilities together, the naive Bayes method yields an extremely small number that frequently cannot be stated as a double or long double. Typically, log-probabilities are used as a remedy for this problem. The factors given make the log-probabilities function neatly.\n",
    "\n",
    "The log of the product is the sum of the logs, just as we can add the logs. The resulting sums (rather than products in the case of probabilities) are often manageable, as opposed to the exceedingly small number in the case of just probabilities.\n",
    "\n",
    "Because probability is always between 0 and 1, log-probabilities have a significantly larger range than [0,1], between -inf and 0.\n",
    "\n",
    "Comparing prob = comparing log probabilites a < b ~ log(a) < log(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d17a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS6120_NLP_Assignment_1_Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
